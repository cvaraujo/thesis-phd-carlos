\chapter{Preliminary Concepts}\label{chp:preliminary-concepts}

In this chapter, we introduce the fundamental concepts necessary for
understanding this thesis. In this work, we employ basic concepts from
Combinatorial Optimization, which are assumed to be known. If the reader deems a
review necessary, we recommend the textbook by Nemhauser and
Wolsey~\cite{Nemhauser}, which covers this topic with a focus on \gls{ilp}, one
of the main tools used in this work. Basic concepts related to graph theory are
also assumed to be known. Should the reader require a refresher, the material
can be found in standard textbooks on the subject, such as
Diestel~\cite{diestel:2005}.

% TODO: add references to the sections
% The mathematical models are presented in Sections~\ref{sec:dmfm-pma}
% and~\ref{sec:ab-pma}. Section~\ref{sec:rel-lagrangiana} provides a description
% of the functioning and application of Lagrangian relaxation, one of the main
% approaches employed in this work. Finally, in Sections~\ref{sec:metaheuristic}
% and~\ref{subsec:brkga}, we present a general discussion on metaheuristics.

\section{Notations and Definitions}\label{sec:not-e-def}

Let $G = (V, A, B)$ be a weighted and directed graph, where $V = \{1, \dots,
	n\}$ is the set of vertices, $A = \{(i, j) : i, j \in V, i \neq j\}$ is the
set of $m$ arcs, and $B = \{b : b \subseteq V\}$ is the set of blocks. In
each arc, the first vertex is the source and also the predecessor of the
second vertex in the ordered pair, which is known as the destination. Each
block $b$ has an associated set of arcs $B(i, j) \subseteq A$ that can be
serviced by a vehicle. 

We now present a formal definition of the \gls{cbrp}. Let a Plannar Graph,
extracted from a real citymap, be represented as a weighted directed graph $G$.
Each node in $V$ represents the intersection of at least two streets and has a
list of blocks $b \subseteq B$ that are associated with it. Each arc $(i, j) \in
	A$ has a deadheading time $t_{i, j} > 0$, a service time $t^{'}_{i, j} > 0$ such
that $t_{i, j} \leqslant t^{'}_{i, j}$ and the block $b \in B$ that is
associated with it. The input to the \gls{cbrp} is defined as:

\begin{itemize}
	\item $G = (V, A, B)$ is a weighted directed planar graph with the blocks associated with it;
	\item $p_b : B \rightarrow \mathbb{N}$ is a function that returns the profit
	      for each block $b \in B$;
	\item $t_{i, j} : A \rightarrow \mathbb{N}$ is a function that returns the
	      deadheading time for each arc $(i, j) \in A$;
	\item $t^{'}_{i, j} : A \rightarrow \mathbb{N}$ is a function that returns
	      the service time for each arc $(i, j) \in A$;
	\item $T$ is the time limit for the vehicle to travel and service the blocks;
	\item $V(b)$ is the set of nodes that are associated with the block $b \in B$;
	\item $B(i)$ is the set of blocks that are associated with the node $i \in V$;
	\item $B(i, j)$ is the set of blocks that are associated with the arc $(i, j) \in A$;
	\item $\delta^{+}_{i}$ is the set of arcs with destination $i$;
	\item $\delta^{-}_{i}$ is the set of arcs with source $i$;
\end{itemize}

The \gls{cbrp} is introduced as a general framework for addressing the routing
of spraying vehicles and other city block servicing problems. The objective of
the \gls{cbrp} is to determine an optimal traversal that services a subset of
blocks within a network, maximizing the total collected benefit from each
serviced block. A vehicle traverses the graph $G$ following a route that can
serve a subset of blocks within a given time limit $T$. This work considers two
types of solution routes, depending on whether the vertices can be visited more
than once: \textit{Walk-based route}, in which any vertex (or arc) can be
visited multiple times and \textit{Path-based route}, in which no vertex appears
more than once. An optimal route (walk or path) is one that maximizes the total
prize collected from the serviced blocks while respecting the vehicle time limit
$T$.

To facilitate modeling, we augment the graph $G$ by introducing a dummy depot
$0$, from which the route originates, and a set of arcs $\{(0, i), (i, 0) :
	\forall i \in V\}$ with times $t_{i,0} = t_{0,i} = 0$, $\forall i \in V$. Thus,
we define the modified graph as $G' = (V' = V \cup \{0\}, A' = A \cup \{(0, i),
	(i, 0) : \forall i \in V\})$.

We now present key properties of the \gls{cbrp}. First, due to the operational
restrictions, once a block $b$ starts being serviced at a given node $i$, it
must be fully encircled before the vehicle moves to another block. This leads to
the following property:

\begin{property}
	\label{claim:core_insight}
	A block can be serviced if at least one of its nodes is visited.
\end{property}

From Property~\ref{claim:core_insight}, when formulating the problem, it is not
necessary to explicitly require the vehicle to completely traverse a block's
perimeter in order to count it as serviced. Instead, servicing can be achieved
by visiting at least one node within the block and accounting for the
corresponding service time. This property is valid due to the definition of the
blocks $B$ and the fact that the vehicle must service all blocks in a clockwise
direction.

Figure~\ref{fig:servicing_block_no_surrounding_strategy} illustrates an example
of this strategy, where servicing is achieved without requiring a full traversal
of the block's perimeter.

\begin{figure}[h!]
	\begin{minipage}[c]{.31\textwidth}
		\begin{tikzpicture}[
				> = stealth, % arrow head style
				shorten > = 0.8pt, % don't touch arrow head to node
				auto,
				node distance = 1.3cm, % distance between nodes
				semithick % line style
			]
			
			\tikzstyle{every state}=[
			draw = black,
			thick,
			fill = white,
			minimum size = 9mm
			]
			
			\node[state] (a) at (0,0) {$1$};
			\node[state, right of = a] (b) {$2$};
			\node[state, above of = a] (c) {$3$};
			\node[state, above of = b] (d) {$4$};
			
			\node[state, right of = b, xshift=0.1cm] (e) {$5$};
			\node[state, right of = d, xshift=0.1cm] (f) {$6$};
			\node[state, right of = e] (g) {$7$};
			\node[state, right of = f] (h) {$8$};
			
			\node[state, below of = b, yshift=-0.5cm] (i) {$9$};
			\node[state, below of = e, yshift=-0.5cm] (j) {$10$};
			\node[state, below of = i, left of = j, xshift=0.6cm] (k) {$11$};
			
			\path[->, draw = gray, opacity = 0.2] (a) edge node {} (c); 
			\path[->, draw = gray, opacity = 0.2] (c) edge node {} (d); 
			\path[->, draw = gray, opacity = 0.2] (d) edge node {} (b);
			\path[->, draw = gray, opacity = 0.2] (b) edge node {} (a);
			
			\path[->, draw = gray, opacity = 0.2] (e) edge node {} (f);
			\path[->, draw = gray, opacity = 0.2] (f) edge node {} (h);
			\path[->, draw = gray, opacity = 0.2] (h) edge node {} (g);
			\path[->, draw = gray, opacity = 0.2] (g) edge node {} (e);
			
			\path[->, draw = gray, opacity = 0.2] (i) edge node {} (j);
			\path[->, draw = gray, opacity = 0.2] (j) edge node {} (k);
			\path[->, draw = gray, opacity = 0.2] (k) edge node {} (i);
			
			\path[->, draw = gray, opacity = 0.2, dashed] (j) edge node {} (b);
			\path[->, draw = gray, opacity = 0.2, dashed] (b) edge node {} (e);
		\end{tikzpicture}
		\subcaption{Instance Example.}
	\end{minipage}
	\hfill
	\begin{minipage}[c]{.31\textwidth}
		\begin{tikzpicture}[
				> = stealth, % arrow head style
				shorten > = 0.8pt, % don't touch arrow head to node
				auto,
				node distance = 1.3cm, % distance between nodes
				semithick % line style
			]
			
			\tikzstyle{every state}=[
			draw = black,
			thick,
			fill = white,
			minimum size = 9mm
			]
			
			\node[state] (a) at (0,0) {$1$};
			\node[state, right of = a] (b) {$2$};
			\node[state, above of = a] (c) {$3$};
			\node[state, above of = b] (d) {$4$};
			
			\node[state, right of = b, xshift=0.1cm] (e) {$5$};
			\node[state, right of = d, xshift=0.1cm] (f) {$6$};
			\node[state, right of = e] (g) {$7$};
			\node[state, right of = f] (h) {$8$};
			
			\node[state, below of = b, yshift=-0.5cm] (i) {$9$};
			\node[state, below of = e, yshift=-0.5cm] (j) {$10$};
			\node[state, below of = i, left of = j, xshift=0.6cm] (k) {$11$};
			
			\path[->, draw = gray, opacity = 1.0] (a) edge node {} (c); 
			\path[->, draw = gray, opacity = 1.0] (c) edge node {} (d); 
			\path[->, draw = gray, opacity = 1.0] (d) edge node {} (b);
			\path[->, draw = gray, opacity = 1.0] (b) edge node {} (a);
			
			\path[->, draw = gray, opacity = 1.0] (e) edge node {} (f);
			\path[->, draw = gray, opacity = 1.0] (f) edge node {} (h);
			\path[->, draw = gray, opacity = 1.0] (h) edge node {} (g);
			\path[->, draw = gray, opacity = 1.0] (g) edge node {} (e);
			
			\path[->, draw = gray, opacity = 1.0] (i) edge node {} (j);
			\path[->, draw = gray, opacity = 1.0] (j) edge node {} (k);
			\path[->, draw = gray, opacity = 1.0] (k) edge node {} (i);
			
			\path[->, draw = gray, opacity = 1.0, dashed] (j) edge node {} (b);
			\path[->, draw = gray, opacity = 1.0, dashed] (b) edge node {} (e);
		\end{tikzpicture}
		\subcaption{Explicity Block Servicing.}
	\end{minipage}
	\hfill
	\begin{minipage}[c]{.31\textwidth}
		\begin{tikzpicture}[
				> = stealth, % arrow head style
				shorten > = 0.8pt, % don't touch arrow head to node
				auto,
				node distance = 1.3cm, % distance between nodes
				semithick % line style
			]
			
			\tikzstyle{every state}=[
			draw = black,
			thick,
			fill = white,
			minimum size = 9mm
			]
			
			\node[state] (a) at (0,0) {$1$};
			\node[state, right of = a] (b) {$2$};
			\node[state, above of = a] (c) {$3$};
			\node[state, above of = b] (d) {$4$};
			
			\node[state, right of = b, xshift=0.1cm] (e) {$5$};
			\node[state, right of = d, xshift=0.1cm] (f) {$6$};
			\node[state, right of = e] (g) {$7$};
			\node[state, right of = f] (h) {$8$};
			
			\node[state, below of = b, yshift=-0.5cm] (i) {$9$};
			\node[state, below of = e, yshift=-0.5cm] (j) {$10$};
			\node[state, below of = i, left of = j, xshift=0.6cm] (k) {$11$};
			
			\path[->, draw = gray, opacity = 0.2] (a) edge node {} (c); 
			\path[->, draw = gray, opacity = 0.2] (c) edge node {} (d); 
			\path[->, draw = gray, opacity = 0.2] (d) edge node {} (b);
			\path[->, draw = gray, opacity = 0.2] (b) edge node {} (a);
			
			\path[->, draw = gray, opacity = 0.2] (e) edge node {} (f);
			\path[->, draw = gray, opacity = 0.2] (f) edge node {} (h);
			\path[->, draw = gray, opacity = 0.2] (h) edge node {} (g);
			\path[->, draw = gray, opacity = 0.2] (g) edge node {} (e);
			
			\path[->, draw = gray, opacity = 0.2] (i) edge node {} (j);
			\path[->, draw = gray, opacity = 0.2] (j) edge node {} (k);
			\path[->, draw = gray, opacity = 0.2] (k) edge node {} (i);
			
			\path[->, draw = gray, opacity = 1.0, dashed] (j) edge node {} (b);
			\path[->, draw = gray, opacity = 1.0, dashed] (b) edge node {} (e);
		\end{tikzpicture}
		\subcaption{Implicit Block Servicing.}
	\end{minipage}
	\caption{\label{fig:servicing_block_no_surrounding_strategy} Strategies for servicing blocks.}
\end{figure}

Assuming the implicit servicing of a block as allowed by
Property~\ref{claim:core_insight}, additional properties can be established
concerning optimal solutions. Let $V_B = \bigcup_{b \in B} V(b)$ be the set of
nodes belonging to some city block, and let $S^{*} = (v_1, \ldots v_n)$
represent an optimal route.

\begin{property}
	\label{lemma_solution_extremities}
	There exists an optimal route $S^{*}$ with both extremities in $V_B$.
\end{property}

\begin{proof}
	Suppose $S^{*}$ does not have both extremities in $V_B$. By removing the
	prefix and/or suffix of $S^{*}$ whose nodes do not belong to $V_B$, we
	obtain another solution that preserves the total collected prize and does
	not increase the total time spent, since $t_a \geqslant 0$.
\end{proof}

\section{Deterministic Optimization Models}\label{sec:cbrp-deterministic-models}

Given an instance for the \gls{cbrp}, consider a path-based solution on the
original planar graph, in which no arc or vertex is visited more than once. The
following binary decision variables are introduced for the model:

\begin{itemize}
	\item $x_{ij} \in \{0, 1\}$ is a binary variable that indicates whether the arc $(i, j) \in A'$ is included in the route ($x_{ij} = 1$) or not ($x_{ij} = 0$);
	\item $y_{ib} \in \{0, 1\}$ is a binary variable that indicates whether node $i \in V$ is selected as the starting point for serving block $b \in B(i)$ ($y_{ib} = 1$) or not ($y_{ib} = 0$).
\end{itemize}

A Path-CBRP formulation is defined as follows:
\allowdisplaybreaks

\begin{align}
	\text{(Path-CBRP) }          & \max \sum_{i \in V} \sum_{b \in B} p_b y_{ib}                                             & \label{eq:of}                                                  \\
	\nonumber \text{subject to:} &                                                                                           &                                                                \\
	                             & \sum_{i \in V} x_{0,i} = \sum_{j \in V} x_{j,0} = 1                                       & \label{eq:s-t-all}                                             \\
	%
	                             & \sum_{i \in V} x_{i,j} - \sum_{k \in V} x_{j,k} = 0                                       & \ \forall j \in V \label{eq:flow-conservation}                 \\
	%
	                             & \sum_{i \in V(b)} y_{ib} \leq 1                                                           & \ \forall b \in B \label{eq:max-attend}                        \\
	%
	                             & \sum_{j \in \delta^{-}(i)} x_{i,j} \geq y_{ib}                                            & \ \forall b \in B, i \in V(b) \label{eq:in-path}               \\
	%
	                             & \sum_{(i, j) \in A} x_{i,j}t_{i,j} + \sum_{i \in V} \sum_{b \in B} y_{ib}t^{'}_{b} \leq T & \label{eq:max-time}                                            \\
	                             & \sum_{(i, j) \in A(S)} x_{i,j} \leq |V(S)| - 1                                            & \ \forall S \subseteq V \label{eq:circuit-subtour-elimination} \\	
	                             & x \in \mathbb{B}^{|A'|}                                                                   & \label{eq:dom-x}                                               \\
	                             & y \in \mathbb{B}^{|V'| \times |B|}.                                                       & \label{eq:dom-y}
\end{align}


The Path-CBRP formulation generates a closed path that starts and ends at the
depot. The objective function~\eqref{eq:of} maximizes the total prize collected
from each serviced block.
Constraints~\eqref{eq:s-t-all}-\eqref{eq:flow-conservation} enforce the start
and end of the route at the depot, and the flow conservation at each node, i.e.
the number of arcs entering a node equals to the number of arcs leaving it.
Constraints~\eqref{eq:max-attend} and~\eqref{eq:in-path} ensure that exactly one
node is selected as the starting point for servicing a block.
Constraints~\eqref{eq:max-time} impose a time limit, accounting for differences
in time spent while servicing and traveling.
Constraints~\eqref{eq:circuit-subtour-elimination} prevent the formation of
subcycles. Finally, constraints~\eqref{eq:dom-x} and~\eqref{eq:dom-y} define the
domain of the decision variables.

Since the subcycle elimination constraints are exponentially large in relation
to the input size, there are two most common approaches to solve Path-CBRP: the
first is to apply the subcycle elimination procedure to integer solutions
obtained during the solver branch and bound. The second is to replace the
constraint by a more compact set of constraints based on the \gls{mtz}
formulation.

% TODO: move to a future subsection with more details
% The implementation of the subtour elimination constraint leads to a separation
% heuristic using max-flow/min-cut that is applied in fractional branch and bound
% solutions. Arc capacities are derived from their relaxed LP solution values. The
% sum of arcs in the identified min-cut must carry at least the flow indicated by
% \( y_{ib} \) variables on either side of the cut. The preflow min-cut algorithm
% from the Lemon Library~\citep{lemon:2011} is used.

To implement the \gls{mtz} approach, we introduce the following additional
variable: 

\begin{itemize}
	\item $w_{a} \in \mathbb{R}$ is a real-valued variable representing the accumulated
	      time along the arc $(i, j) \in A'$.
\end{itemize}

Using this variable, it is possible to replace the
constraints~\eqref{eq:circuit-subtour-elimination} by the following set of
constraints:

\begin{align}
	 & w_{j,k} \geq w_{i,j} + x_{i,j}t_{i,j} - (2 - x_{j,k} - x_{i,j})T & \forall (i, j) \in A, (j, k) \in A, j \in V \label{eq:max-time-compact-leq}                               \\
	 & w_{i,0} \leq T                                                   & \forall i \in V.                                                            & \label{eq:max-time-compact}
\end{align}

Constraints~\eqref{eq:max-time-compact-leq} compute the accumulated time at each
arc, while constraints~\eqref{eq:max-time-compact} enforce an upper bound on the
\gls{mtz} variable. This reformulated model maintains an equivalent set of
integer feasible solutions to Path-CBRP while significantly reducing the number
of constraints, which now grows polynomially with respect to the input size.
However, the fractional feasible space may widen, since the number of cuts
reduced from exponential to polynomial. This formulation is referred to as
Path-CBRP-MTZ.

\subsection{Walk-based Formulation}\label{sec:cbrp-walk-based-formulation}

The possibility of visiting a vertex more than once is a significant difference
between the Path-CBRP and the Walk-CBRP. This allows for more flexibility in the
solution, and achieve values always greater than or equal to the Path-CBRP.
\Cref{fig:walk-feasible-solution-example} presents a feasible route for the
Walk-CBRP, that is not feasible for the Path-CBRP. In the example, the route
starts at the depot, then visits node $2$, and goes to node $5$, then goes back
to $2$, does the same to node $10$ and finally ends the route going to node $13$
and depot.


\begin{figure}[h!]
	\begin{minipage}[c]{.4\textwidth}
		\begin{tikzpicture}[
				> = stealth, % arrow head style
				shorten > = 0.8pt, % don't touch arrow head to node
				auto,
				node distance = 1.3cm, % distance between nodes
				semithick % line style
			]
			
			\tikzstyle{every state}=[
			draw = black,
			thick,
			fill = white,
			minimum size = 9mm
			]
			
			\node[state] (a) at (0,0) {$1$};
			\node[state, right of = a] (b) {$2$};
			\node[state, above of = a] (c) {$3$};
			% \node[state, above of = b] (d) {$4$};
			
			\node[state, right of = b, xshift=0.8cm] (e) {$5$};
			\node[state, right of = d, xshift=0.8cm] (f) {$6$};
			\node[state, right of = e] (g) {$7$};
			\node[state, right of = f] (h) {$8$};
			
			\node[state, below of = b, yshift=-0.1cm] (i) {$9$};
			\node[state, below of = e, yshift=-0.1cm] (j) {$10$};
			\node[state, below of = i, left of = j, xshift=0.4cm] (k) {$11$};
			
			\node[state, above of = d, yshift=0.1cm] (l) {$12$};
			\node[state, above of = f, yshift=0.1cm] (m) {$13$};
			\node[state, above of = l, left of = m, xshift=0.4cm] (n) {$14$};
			
			\path[->, draw = gray, opacity = 0.2] (a) edge node {} (c); 
			\path[->, draw = gray, opacity = 0.2] (c) edge node {} (b); 
			\path[->, draw = gray, opacity = 0.2] (b) edge node {} (a);
			
			\path[->, draw = gray, opacity = 0.2] (e) edge node {} (f);
			\path[->, draw = gray, opacity = 0.2] (f) edge node {} (h);
			\path[->, draw = gray, opacity = 0.2] (h) edge node {} (g);
			\path[->, draw = gray, opacity = 0.2] (g) edge node {} (e);
			
			\path[->, draw = gray, opacity = 0.2] (i) edge node {} (j);
			\path[->, draw = gray, opacity = 0.2] (j) edge node {} (k);
			\path[->, draw = gray, opacity = 0.2] (k) edge node {} (i);
			
			\path[->, draw = gray, opacity = 0.2] (l) edge node {} (n);
			\path[->, draw = gray, opacity = 0.2] (n) edge node {} (m);
			\path[->, draw = gray, opacity = 0.2] (m) edge node {} (l);
			
			\path[->, draw = gray, opacity = 0.2, dashed] (b) edge node {} (m);
			\path[->, draw = gray, opacity = 0.2, dashed] (m) edge node {} (b);
			\path[->, draw = gray, opacity = 0.2, dashed] (b) edge node {} (e);
			\path[->, draw = gray, opacity = 0.2, dashed] (e) edge node {} (b);
			\path[->, draw = gray, opacity = 0.2, dashed] (b) edge node {} (j);
			\path[->, draw = gray, opacity = 0.2, dashed] (j) edge node {} (b);
			
		\end{tikzpicture}
		\subcaption{Instance Example.}
	\end{minipage}
	\hfill
	\begin{minipage}[c]{.4\textwidth}
		\begin{tikzpicture}[
				> = stealth, % arrow head style
				shorten > = 0.8pt, % don't touch arrow head to node
				auto,
				node distance = 1.3cm, % distance between nodes
				semithick % line style
			]
			
			\tikzstyle{every state}=[
			draw = black,
			thick,
			fill = white,
			minimum size = 9mm
			]
			
			\node[state] (a) at (0,0) {$1$};
			\node[state, rectangle, double, right of = a] (b) {$2$};
			\node[state, above of = a] (c) {$3$};
			
			\node[state, rectangle, double, right of = b, xshift=0.8cm] (e) {$5$};
			\node[state, right of = d, xshift=0.8cm] (f) {$6$};
			\node[state, right of = e] (g) {$7$};
			\node[state, right of = f] (h) {$8$};
			
			\node[state, below of = b, yshift=-0.1cm] (i) {$9$};
			\node[state, rectangle, double, below of = e, yshift=-0.1cm] (j) {$10$};
			\node[state, below of = i, left of = j, xshift=0.4cm] (k) {$11$};
			
			\node[state, above of = d, yshift=0.1cm] (l) {$12$};
			\node[state, rectangle, double, above of = f, yshift=0.1cm] (m) {$13$};
			\node[state, above of = l, left of = m, xshift=0.4cm] (n) {$14$};
			
			\node[state, double, below of = a, left of = i] (s) {$s$};
			\node[state, double, above of = h, right of = m] (t) {$t$};
			
			\path[->, draw = gray, opacity = 0.2] (a) edge node {} (c); 
			\path[->, draw = gray, opacity = 0.2] (c) edge node {} (b); 
			\path[->, draw = gray, opacity = 0.2] (b) edge node {} (a);
			
			\path[->, draw = gray, opacity = 0.2] (e) edge node {} (f);
			\path[->, draw = gray, opacity = 0.2] (f) edge node {} (h);
			\path[->, draw = gray, opacity = 0.2] (h) edge node {} (g);
			\path[->, draw = gray, opacity = 0.2] (g) edge node {} (e);
			
			\path[->, draw = gray, opacity = 0.2] (i) edge node {} (j);
			\path[->, draw = gray, opacity = 0.2] (j) edge node {} (k);
			\path[->, draw = gray, opacity = 0.2] (k) edge node {} (i);
			
			\path[->, draw = gray, opacity = 0.2] (l) edge node {} (n);
			\path[->, draw = gray, opacity = 0.2] (n) edge node {} (m);
			\path[->, draw = gray, opacity = 0.2] (m) edge node {} (l);
			
			\path[->, draw = black, opacity = 1.0, dashed] (b) edge node {} (m);
			\path[->, draw = black, opacity = 1.0, bend right=10, dashed] (b) edge node {} (e);
			\path[->, draw = black, opacity = 1.0, bend right=10, dashed] (e) edge node {} (b);
			\path[->, draw = black, opacity = 1.0, bend right=10, dashed] (b) edge node {} (j);
			\path[->, draw = black, opacity = 1.0, bend right=10, dashed] (j) edge node {} (b);
			% depot
			\path[->, draw = black, opacity = 1.0, dashed] (s) edge node {} (b);
			\path[->, draw = black, opacity = 1.0, dashed] (m) edge node {} (t);
			
		\end{tikzpicture}
		\subcaption{Walk Solution.}
	\end{minipage}
	\caption{\label{fig:walk-feasible-solution-example} Walk Feasible Solution Example.}
\end{figure}


Given an instance for the \gls{cbrp}, consider a walk-based solution on the
original planar graph, in which an arc or vertex could be visited more than
once. The following binary decision variables are introduced for the model:

\begin{itemize}
	\item $x_{ij} \in \mathbb{Z}$ is an integer variable that indicates the number of times that the arc $(i, j) \in A'$ is traversed in the route;
	\item $y_{b} \in \{0, 1\}$ is a binary variable that indicates whether block $b \in B$ is attended ($y_{b} = 1$) or not ($y_{b} = 0$).
\end{itemize}

A Walk-CBRP formulation is defined as follows:

\begin{align}
	\text{(Walk-CBRP) }          & \max \sum_{b \in B} p_b y_{b}                                             & \label{eq:walk-of}                                                                                 \\
	\nonumber \text{subject to:} &                                                                           &                                                                                                    \\
	                             & \sum_{i \in V} x_{0,i} = \sum_{j \in V} x_{j,0} = 1                       & \label{eq:walk-s-t-all}                                                                            \\
	%
	                             & \sum_{i \in V} x_{i,j} - \sum_{k \in V} x_{j,k} = 0                       & \ \forall j \in V \label{eq:walk-flow-conservation}                                                \\
	%
	                             & \sum_{i \in V(b)} \sum_{j \in \delta^{-}(i)} x_{i,j} \geq y_{b}           & \ \forall b \in B \label{eq:walk-in-path}                                                          \\
	%
	                             & \sum_{(i, j) \in A} x_{i,j}t_{i,j} + \sum_{b \in B} y_{b}t^{'}_{b} \leq T & \label{eq:walk-max-time}                                                                           \\
	                             & \sum_{(i, j) \in \delta^{+}(S)} x_{i,j} \geq x_{k,l} + x_{p,q} - 1        & \forall S \subseteq V, (k, l) \subseteq S, (p, q) \nsubseteq S \label{eq:walk-subtour-elimination} \\	
	                             & x \in \mathbb{Z}^{|A'|}                                                   & \label{eq:walk-dom-x}                                                                              \\
	                             & y \in \mathbb{B}^{|B|}.                                                   & \label{eq:walk-dom-y}
\end{align}

The objective~\eqref{eq:walk-of} maximize the profit collected.
Constraints~\eqref{eq:walk-s-t-all} ensure that the route starts and ends at the
depot. Constraints~\eqref{eq:walk-flow-conservation} ensure the equity of arcs
in each used node. Constraints~\eqref{eq:walk-in-path} ensure the connectivity
to at least one node to any attended block. Constraints~\eqref{eq:walk-max-time}
ensure that the route and the block service time does not exceed the time limit.
Constraints~\eqref{eq:walk-subtour-elimination} ensure that the route does not
contains disconnected subtours. Variables~\eqref{eq:walk-dom-x}
and~\eqref{eq:walk-dom-y} ensure the domain of the variables.

We define, for every pair of arcs $a' = (k, l)$ and $a'' = (p, q)$, the family
of separating sets as
\[
	\mathrm{cut}(a', a'') = \{ S \subset V \mid \{k, l\} \subseteq S, \ \{p, q\} \nsubseteq S \}.
\]

That is, every set $S \in \mathrm{cut}(a', a'')$ contains both endpoints of $a'$
and does not contain the endpoints of $a''$. If two arcs $a'$ and $a''$ are
selected simultaneously, then for every $S \in \mathrm{cut}(a', a'')$ there must
be an outgoing arc from $S$ in the solution.

\subsection{Walk-Solution Using Transitive Closure of the Graph}\label{sec:walk-solution-using-transitive-closure}

In this section, we present an adaptation that consists in the adaptation of
original planar graph that allow us to compute implicit walks using a
formulation presented in Section~\ref{sec:cbrp-deterministic-models}. Our
approach is to construct a new graph in which blocks are transformed into nodes.
Let:

\begin{itemize}
	\item $G' = (V', A')$: be the graph with the node and arcs to the artificial
	      depot $s = 0$.
	\item $P_{i,j}$: be the shortest path from node $i$ to node $j$ in $G$ where
	      $t_{i,j} = t_{P_{i,j}}$, and $t_{i,0} = t_{0,i} = 0$ for all $i \in
		      V$.
	\item $V_B = \bigcup_{b \in B} V(b)$: be the set of nodes belonging to some
	      city block.
	\item $V_B^0 = V_B \cup \{0\}$: represent the set of block nodes along with
	      the artificial depot $0$.
	\item $A_B = A(V_B)$ and $A_B^0 = A(V_B^0)$: be the sets of arcs associated
	      with $V_B$ and $V_B^0$, respectively.
\end{itemize}


The construction of $G_B^0$ (blocks-as-nodes graph) follows from
Lemma~\ref{lemma_solution_extremities}, which considers only nodes in $V_B$ from
the original graph, and from the definition of $P_{i,j}$, ensuring that the
shortest paths between two nodes in $V_B$ are preserved. Together, these
properties guarantee that using $G_B^0$ preserves all optimal solutions of the
\gls{cbrp}.

\Cref{fig:CBRP_transitive_closure_example} illustrates the rationale for using
graph $G_B$. Specifically, \Cref{subfig:CBRP_instance_digraph} presents a
\gls{cbrp} instance, while \Cref{subfig:CBRP_solution_graph_G} shows the
corresponding solution in the original graph, where the dashed arcs represent
the non-spraying travels. Finally, \Cref{subfig:CBRP_solution_graph_G_B}
represents the same solution mapped onto the transformed graph structure.

\begin{figure}[h!]
	\begin{minipage}[c]{.31\textwidth}
		\begin{tikzpicture}[
				> = stealth, % arrow head style
				shorten > = 0.8pt, % don't touch arrow head to node
				auto,
				node distance = 1.3cm, % distance between nodes
				semithick % line style
			]
			
			\tikzstyle{every state}=[
			draw = black,
			thick,
			fill = white,
			minimum size = 8mm
			]
			
			\node[state] (a) at (0,0) {$1$};
			\node[state, right of = a] (b) {$2$};
			\node[state, above of = a] (c) {$3$};
			
			\node[state, right of = b, xshift=0.1cm] (d) {$4$};
			
			\node[state, right of = d, xshift=0.1cm] (e) {$5$};
			\node[state, above of = d, xshift=0.1cm] (f) {$6$};
			\node[state, above of = e] (g) {$7$};
			
			\node[state, above of = f, xshift=-0.8cm] (h) {$8$};
			\node[state, above of = h] (i) {$9$};
			\node[state, left of = i] (j) {$10$};
			\node[state, below of = j] (k) {$11$};
			
			\path[->, draw = gray, opacity = 0.2] (a) edge node {} (c); 
			\path[->, draw = gray, opacity = 0.2] (c) edge node {} (b); 
			\path[->, draw = gray, opacity = 0.2] (b) edge node {} (a);
			
			\path[->, draw = gray, opacity = 0.2] (b) edge node {} (d);
			\path[->, draw = gray, opacity = 0.2] (d) edge node {} (e);
			
			\path[->, draw = gray, opacity = 0.2] (e) edge node {} (f);
			\path[->, draw = gray, opacity = 0.2] (f) edge node {} (g);
			\path[->, draw = gray, opacity = 0.2] (g) edge node {} (e);
			
			\path[->, draw = gray, opacity = 0.2] (h) edge node {} (k);
			\path[->, draw = gray, opacity = 0.2] (k) edge node {} (j);
			\path[->, draw = gray, opacity = 0.2] (j) edge node {} (i);
			\path[->, draw = gray, opacity = 0.2] (i) edge node {} (h);
			
			\path[->, draw = gray, opacity = 0.2] (f) edge node {} (h);
		\end{tikzpicture}
		\subcaption{\label{subfig:CBRP_instance_digraph} Instance Example.}
	\end{minipage}
	\hfill
	\begin{minipage}[c]{.31\textwidth}
		\begin{tikzpicture}[
				> = stealth, % arrow head style
				shorten > = 0.8pt, % don't touch arrow head to node
				auto,
				node distance = 1.3cm, % distance between nodes
				semithick % line style
			]
			
			\tikzstyle{every state}=[
			draw = black,
			thick,
			fill = white,
			minimum size = 8mm
			]
			
			\node[state] (a) at (0,0) {$1$};
			\node[state, right of = a] (b) {$2$};
			\node[state, above of = a] (c) {$3$};
			
			\node[state, right of = b, xshift=0.1cm] (d) {$4$};
			
			\node[state, right of = d, xshift=0.1cm] (e) {$5$};
			\node[state, above of = d, xshift=0.1cm] (f) {$6$};
			\node[state, above of = e] (g) {$7$};
			
			\node[state, above of = f, xshift=-0.8cm] (h) {$8$};
			\node[state, above of = h] (i) {$9$};
			\node[state, left of = i] (j) {$10$};
			\node[state, below of = j] (k) {$11$};
			
			\path[->, draw = gray, opacity = 0.2] (a) edge node {} (c); 
			\path[->, draw = gray, opacity = 0.2] (c) edge node {} (b); 
			\path[->, draw = gray, opacity = 0.2] (b) edge node {} (a);
			
			\path[->, draw = black, opacity = 1.0, dashed] (b) edge node {} (d);
			\path[->, draw = black, opacity = 1.0, dashed] (d) edge node {} (e);
			
			\path[->, draw = black, opacity = 1.0, dashed] (e) edge node {} (f);
			\path[->, draw = gray, opacity = 0.2] (f) edge node {} (g);
			\path[->, draw = gray, opacity = 0.2] (g) edge node {} (e);
			
			\path[->, draw = gray, opacity = 0.2] (h) edge node {} (k);
			\path[->, draw = gray, opacity = 0.2] (k) edge node {} (j);
			\path[->, draw = gray, opacity = 0.2] (j) edge node {} (i);
			\path[->, draw = gray, opacity = 0.2] (i) edge node {} (h);
			
			\path[->, draw = black, opacity = 1.0, dashed] (f) edge node {} (h);
		\end{tikzpicture}
		\subcaption{\label{subfig:CBRP_solution_graph_G} Solution on Graph $G$.}
	\end{minipage}
	\hfill
	\begin{minipage}[c]{.31\textwidth}
		\begin{tikzpicture}[
				> = stealth, % arrow head style
				shorten > = 0.8pt, % don't touch arrow head to node
				auto,
				node distance = 1.3cm, % distance between nodes
				semithick % line style
			]
			
			\tikzstyle{every state}=[
			draw = black,
			thick,
			fill = white,
			minimum size = 8mm
			]
			
			\node[state] (a) at (0,0) {$1$};
			\node[state, right of = a] (b) {$2$};
			\node[state, above of = a] (c) {$3$};
			
			% \node[state, right of = b, xshift=0.2cm] (d) {$4$};
			
			\node[state, right of = d, xshift=0.1cm] (e) {$5$};
			\node[state, above of = d, xshift=0.1cm] (f) {$6$};
			\node[state, above of = e] (g) {$7$};
			
			\node[state, above of = f, xshift=-0.8cm] (h) {$8$};
			\node[state, above of = h] (i) {$9$};
			\node[state, left of = i] (j) {$10$};
			\node[state, below of = j] (k) {$11$};
			
			\path[->, draw = gray, opacity = 0.2] (a) edge node {} (c); 
			\path[->, draw = gray, opacity = 0.2] (c) edge node {} (b); 
			\path[->, draw = gray, opacity = 0.2] (b) edge node {} (a);
			
			\path[->, draw = black, opacity = 1.0, dashed] (b) edge node {} (f);
			
			\path[->, draw = gray, opacity = 0.2] (e) edge node {} (f);
			\path[->, draw = gray, opacity = 0.2] (f) edge node {} (g);
			\path[->, draw = gray, opacity = 0.2] (g) edge node {} (e);
			
			\path[->, draw = gray, opacity = 0.2] (h) edge node {} (k);
			\path[->, draw = gray, opacity = 0.2] (k) edge node {} (j);
			\path[->, draw = gray, opacity = 0.2] (j) edge node {} (i);
			\path[->, draw = gray, opacity = 0.2] (i) edge node {} (h);
			
			\path[->, draw = black, opacity = 1.0, dashed] (f) edge node {} (h);
		\end{tikzpicture}
		\subcaption{\label{subfig:CBRP_solution_graph_G_B} Solution on Graph $G_B$.}
	\end{minipage}
	\caption{\label{fig:CBRP_transitive_closure_example} Solution with Transitive Closure.}
\end{figure}

This adaptation in the original graph allows us to use any \gls{cbrp} fomulation
presented in Section~\ref{sec:cbrp-deterministic-models} in $G_B$ and generate a
implicit walk solution, i.e., a solution that is a path in $G_B$, however when
the arcs represented by shortest paths are converted to real arcs in the
original graph $G$, the solution could turn into a walk. However, this
adjustment demands the creation of all arcs between nodes in $V_B$, fact that
could increase significantly the size of $G_B$ according to the number of blocks
in the instance.

% As there is an exponential number of
% constraints~\eqref{eq:walk-subtour-elimination}, we initially do not add any of
% this type to the model. For each integer solution found, we use connected
% components to check for violations: Since we allow isolated nodes, we only
% consider as components those sets containing at least two nodes. If there is
% more than one component with two or more nodes, the route is not connected; in
% this case, we add a constraint~\eqref{eq:walk-subtour-elimination} to cut off
% the solution, using one of the components $S$ found, along with arcs $a'$ whose
% endpoints belong to $S$, and arcs $a''$ whose endpoints do not belong to $S$.

\section{Lagrangean Relaxation}\label{sec:cbrp-lagrangean-relaxation}

\gls{lr} is a well-known decomposition method used to solve combinatorial
optimization problems. The main idea of \gls{lr} is to remove complicated
constraints from the mathematical model and transfer them to the objective
function by assigning them weights (known as Lagrange multipliers), which
penalize their violation in any solution. It can be shown that the cost of an
optimal solution to the \gls{lr} always provides a dual bound for the optimal
value of the original problem. A primal bound can be obtained by checking the
feasibility of a solution returned by the relaxed model and computing the value
of the original objective function for that solution. An important step in
\gls{lr} is determining the values of the Lagrange multipliers that yield the
best dual bound. For this purpose, the subgradient method can be employed, which
is an iterative procedure in which the multipliers are updated until they
converge to their optimal values. For a minimization problem, this method can be
interpreted as the maximization of the lower bound obtained from the relaxed
model based on appropriate choices of multipliers~\cite{Beasley:1993}.

\gls{lr} is particularly convenient for problems that, apart from a subset of
complicating constraints, can be efficiently solved. For instance, consider the
following \gls{ilp} model:

\begin{align*}
	\text{(IP) } &              &  & z = \min cx           &  &  &  &  &  &  &  &   \\
	             & \text{s.t. } &  & Ax \geq b,            &  &  &  &  &  &  &  &   \\
	             &              &  & Dx \geq d,            &  &  &  &  &  &  &  &   \\
	             &              &  & x \in \mathbb{Z}^n_+. &  &  &  &  &  &  &  & 
\end{align*}

Assuming $Dx \geq d$ is the set of complicating constraints, removing it yields
$z' = \min \{cx : x \in X\}$, where $X = \{x \in \mathbb{Z}^n_+ : Ax \geq b\}$,
which is an easier problem and referred to as the relaxed problem. Two facts can
be observed. First, $z'$ is a lower (dual) bound on $z$, since the feasible
region of $x$ is larger, so the optimal value of $z'$ is less than or equal to
that of $z$. Second, the optimal solution in $X$ may not satisfy the constraints
in $Dx \geq d$. Based on these observations, the idea is to move the
complicating constraints into the objective function, penalizing their violation
using a vector $u \in \mathbb{R}^{m}_+$. This results in the Lagrangian
relaxation problem (\gls{lpp}), which can be written as:

\begin{align*}
	\text{LR($u$) } &              &  & z(u) = \min cx + u(d - Dx) &  &  &  &  &  &  &   \\
	                & \text{s.t. } &  & x \in X,                   &  &  &  &  &  &  &   \\
	                &              &  & u \in \mathbb{R}^m_+.      &  &  &  &  &  &  & 
\end{align*}

The following proposition establishes the relationship between $z(u)$ and $z$.

\begin{proposition}
	Let $z(u) = \min \{cx + u (d - Dx) : x \in X\}$. Then, $z(u) \leq z$ for all $u \geq 0$.
\end{proposition}

The penalty $u_i$ associated with constraint $D_ix \geq d_i$ is called the
Lagrange multiplier for that constraint. We now define the following problem:
determine the set of multipliers that provide the best (i.e., greatest) dual
bound $z(u)$. To find these values, we must solve the Lagrangian dual problem
(\gls{ldp}), described as:

\begin{align*}
	\text{LD } &  &  & w = \max \{z(u) : u \geq 0\}. &  &  &  &  & 
\end{align*}

The Lagrangian dual can be solved using the subgradient optimization method,
which is based on the following result.

\begin{proposition} \label{proposition:convex}
	A function $g : \mathbb{R}^n \rightarrow \mathbb{R}$ is concave if and only if, for every $\bar{x} \in \mathbb{R}^n$, there exists $s \in \mathbb{R}^n$ such that $g(\bar{x}) + s(x - \bar{x}) \geq g(x)$ for all $x \in \mathbb{R}^n$.
\end{proposition}

Thus, at point $\bar{x}$, it is necessary to choose a direction in which to move
to increase $g(x)$. From Proposition~\ref{proposition:convex}, we know that if
$g(x) > g(\bar{x})$, then $s(x - \bar{x}) > 0$. That is, moving an appropriate
amount in the direction of $s$ from $\bar{x}$ will increase the value of $g$.
Therefore, we must find a vector $s$ that satisfies
Proposition~\ref{proposition:convex}. When $g$ is differentiable at $\bar{x}$,
we can take $s = \nabla g(\bar{x})$, i.e., the gradient of $g$ at $\bar{x}$.
However, when $g$ is not differentiable, Proposition~\ref{proposition:convex}
still guarantees the existence of a vector $s$ such that $s(x^* - \bar{x}) > 0$
for an optimal point $x^*$. This means it is possible to move from $\bar{x}$ a
small step in the direction of $s$ to get closer to an optimal point, even if
$g$ does not increase. Before finding such a vector $s$, we define the notions
of subgradient and subdifferential.

\begin{definition}\label{definition:subgradient}
	Let $g : \mathbb{R}^n \rightarrow \mathbb{R}$ be a concave function. A vector $s$ is a subgradient of $g$ at $\bar{x}$ if and only if $s(x - \bar{x}) \geq g(x) - g(\bar{x})$ for all $x \in \mathbb{R}^n$. The subdifferential $(\delta g(\bar{x}))$ of $g$ at $\bar{x}$ is the set of all subgradients at that point.
\end{definition}

An immediate consequence of the above is the following:

\begin{proposition}\label{proposition:optimal}
	If $g$ is concave and $0 \in \delta g(x^*)$, then $g(x^*) = \max\{g(x) : x \in \mathbb{R}^n\}$, that is, $x^*$ is an optimal solution.
\end{proposition}

Therefore, in theory, to maximize a concave function $g$, it is sufficient to
start from any point and iteratively take small steps in the direction of a
subgradient at that point until $0$ belongs to the subdifferential of the
current point—that is, the current point is optimal. The results below allow us
to apply this theory to the Lagrangian relaxation technique for \gls{ilp}.

\begin{proposition} \label{proposition-zu-convex}
	$z(u) = \min \{cx + u (d - Dx)\}$ is concave.
\end{proposition}

The next result shows how to compute a subgradient of $z(u) = \min \{cx + u (d -
	Dx) : x \in X\}$ at point $u$.

\begin{proposition}
	Let $\bar{x} \in X$ such that $z(u) = c \bar{x} + u(d - D\bar{x})$. Then, $(d - D\bar{x})$ is a subgradient of $z(u)$ at $u$.
\end{proposition}

Based on the previous definitions and results, we can now present a procedure to
minimize a concave function for which a subgradient is known at all points in
its domain. For this purpose, a high-level pseudocode of the subgradient method
is presented in Algorithm~\ref{code:subgradient}.

\begin{algorithm}[!ht]
	\caption{\label{code:subgradient} Subgradient Method (Minimization Problem)}
	\Input{threshold, maxIter, updatePi}
	\Output{$z_{LB}$, $z_{UB}$}
	$m \leftarrow \rho \leftarrow 0$\;
	$z_{LB} \leftarrow 0$\;
	$z_{UB} \leftarrow$ cost of a feasible solution\;
	$\alpha^{0} \leftarrow \theta^{0} \leftarrow 0$\; $\pi^{0} \leftarrow 2$\;
	
	\While{$(\frac{z_{UB} - z_{LB}}{Z_{UB}}) \leq \ threshold$  or $m \ < \ maxIter$}{
		$x \leftarrow$ solution of $LR(\alpha^{m})$\;
		$z^{m} \leftarrow$ cost of the objective function of $x$ \;
		\If{$z^{m} > z_{LB}$}{
			$z_{LB} \leftarrow z^{m}$\;
		}
		$z_f^m \leftarrow$ original objective function value of solution $x$\;
		\uIf{$x$ is feasible and $z_f^m < z_{UB}$}{
			$z_{UB} \leftarrow z_f^m$\;
			$\rho \leftarrow 0$\;
		} \Else {
			$\rho \leftarrow \rho + 1$\;
		}
		
		\If{$\rho \ = \ updatePi$}{
			$\pi \leftarrow \pi/2$\;
			$\rho \leftarrow 0$\;
		}
		
		$\theta^{m} \leftarrow$ subgradient($x$)\;
		$n^{m} \leftarrow $ norm($\theta^{m}$)\;
		$s^{m} \leftarrow \pi^{m} \frac{(z_{UB} - z^{m})}{(n^{m})^{2}}$\;
		
		$\alpha^{m+1} \leftarrow \max(0, \alpha^{m} + s^{m}\theta^{m})$\;
		
		$m \leftarrow m + 1$\;
	}
\end{algorithm}

The algorithm takes three input parameters: `threshold', `maxIter', and
`updatePi'. The first two are stopping criteria. The `threshold' indicates the
maximum gap value for the solution to be considered optimal, terminating the
execution. The `maxIter' limits the maximum number of iterations of the
subgradient method. The third parameter, `updatePi`, is a counter for updating
the value of $\pi$, i.e., when `updatePi` consecutive iterations occur without
improvement in the dual bound. Lines (1)–(5) represent the initialization of
variables: $m$ is the main loop counter, and $\rho$ counts consecutive
iterations without improvement in $z_{UB}$. The variables $z_{LB}$ and $z_{UB}$
are the lower and upper bounds, respectively. 

The symbol $\alpha$ represents the vector of Lagrange multipliers, and $\theta$
is the subgradient vector. First, the Lagrangian primal problem is solved using
the current multipliers, and this solution is used to obtain the subgradient. If
the relaxed model returns a better feasible solution (lower in value), $z_{UB}$
is updated; if the solution is feasible for the original problem, $z_{LB}$ is
updated with the value of the original objective function, disregarding the cost
of the multipliers. The subgradient vector ($\theta^m$) is then calculated, and
its norm ($n^m$) is used to compute the step size ($s^m$) in the subgradient
direction. The Lagrange multipliers are then updated for the next iteration.
Line (26) ensures non-negativity of the multipliers.

In this work, we developed three Lagrangean relaxations based on the
Path-CBRP-MTZ model. An important detail to consider is the resolution of the
lagrangean relaxations when the constraints~\eqref{eq:in-path},
\eqref{eq:max-time} and \eqref{eq:max-time-compact}  are dualized, being treated
in the \gls{lpp}, i.e., when this problem becomes a shortest path problem with
resource constraints and a selection/Knapsack problem on $y$ variables.

\section{Optimization Under Uncertainty}\label{sec:optimization-under-uncertainty}

This Section presents the basic concepts of Stochastic Programming and is
strongly based on the textbook by Birge and Louveaux~\cite{birge:2011}.

Two-Stage Stochastic Programming models with recourse deal with uncertain data,
represented by random variables. A decision must be made at the present time; we
call this the first-stage (or first-phase) decision, and at a later time, after
its implementation, the uncertainties are revealed. Then, based on the
first-stage decision and the revealed uncertain data, we can make a corrective
(recourse) decision, called the second-stage (or second-phase)
decision~\cite{birge:2011}.

The uncertain data of the problem are represented by a random vector~$\xi$. We
are interested in the case where~$\xi$ is a discrete random variable, that is,
it can take values from a finite set $\Xi = \{\xi_{1}, \ldots, \xi_{k}\}$. We
denote each possible random event by $\omega \in \Omega$. Alternatively, $\xi$
can be represented as a function of $\omega \in \Omega$, with $\xi(\omega)$
being the value taken by the random variable when event $\omega$ occurs.

First-stage decision variables are represented by vector~$x$, of
dimension~$n_{1}$, while second-stage decision variables are represented by the
random vector~$y$, of dimension~$n_{2}$. We denote by $y(\omega)$ the
second-stage decision variables associated with the realization of random
event~$\omega$.

A traditional two-stage stochastic programming problem, also called a \gls{rp}
or \emph{here-and-now} problem, since a decision must be made in the present
before the uncertainties are revealed, is formulated as:
\begin{align}
	\max \quad        & c^{T} x + \mathbb{E}_{\xi} \left[ \max q(\omega)^{T} y(\omega) \right] \nonumber \\
	\text{s.t.} \quad & A x = b \nonumber                                                                \\
	                  & T(\omega)x + W y(\omega) = h(\omega) \nonumber                                   \\
	                  & x \geq 0 \nonumber                                                               \\
	                  & y(\omega) \geq 0
	\label{eq:rp}
\end{align}

The first-stage data matrices and vectors $A$, $b$, and $c$ have dimensions
$m_{1} \times n_{1}$, $m_{1}$, and $n_{1}$, respectively. Once uncertainties are
revealed through the realization of event $\omega \in \Omega$, $T(\omega)$,
$h(\omega)$, and $q(\omega)$, with dimensions $m_{2} \times n_{1}$, $m_{2}$, and
$n_{2}$, respectively, become known. To represent the problem's uncertainties as
a single random vector, we define
\[
	\xi(\omega)^{T} = \left(q(\omega)^{T}, \; h(\omega)^{T}, \; T_{1\cdot}(\omega), \ldots, T_{m_{2}\cdot}(\omega) \right),
\]
for every $\omega \in \Omega$, where $T_{i\cdot}(\omega)$ denotes the $i$-th row
of matrix $T(\omega)$. We are interested in the class of \emph{fixed recourse
	problems}~\cite{birge:2011}, in which the matrix $W$, of dimension $m_{2}
	\times n_{2}$, represents the second-stage actions and does not depend on the
realization of the random event, and is thus known before making the first-stage
decision.

Note that the objective function in~\eqref{eq:rp} has a deterministic term
$c^{T}x$ and the expected value of $q(\omega)^{T} y(\omega)$ over all
realizations~$\omega$. What makes solving a two-stage stochastic program
difficult is that, for each $\omega \in \Omega$, determining $y(\omega)$
requires solving a \gls{lp} (or \gls{ilp}) problem. To make this more explicit,
an alternative notation for the same problem is known as the \emph{deterministic
	equivalent program}. For a given realization~$\omega$ and first-stage
decision~$x$, we define:
\[
	Q(x, \xi(\omega)) = \max_{y} \left\{ q(\omega)^{T} y \; \middle| \; W y = h(\omega) - T(\omega) x, \; y \geq 0 \right\},
\]
as the second-stage value function. Then, the expected second-stage value for
the first-stage decision~$x$ is:
\[
	Q(x) = \mathbb{E}_{\xi} \left[ Q(x, \xi) \right].
\]
With this, the deterministic equivalent program can be formulated as:
\begin{align}
	\max \quad        & c^{T} x + Q(x) \nonumber \\
	\text{s.t.} \quad & A x = b \nonumber        \\
	                  & x \geq 0.
	\label{eq:rp_det}
\end{align}

\subsection{Expected Value of Perfect Information (EVPI)}

The \gls{evpi} measures the maximum amount a decision-maker would be willing to
pay to have perfect foresight of the future. This allows determining to what
extent a more accurate forecast would improve the quality of the obtained
solution. Consider:
\begin{align}
	\max \quad        & z(x, \xi(\omega)) = c^{T} x + Q(x, \xi(\omega)) \nonumber \\
	\text{s.t.} \quad & A x = b \nonumber                                         \\
	                  & x \geq 0,
	\label{eq:scenario_problem}
\end{align}
which is the optimization problem for a given scenario $\xi(\omega)$. We assume
that for every $\xi(\omega) \in \Xi$, this problem is neither infeasible nor
unbounded.

Suppose there is an efficient way to obtain an optimal solution
$\bar{x}(\xi(\omega))$ to~\eqref{eq:scenario_problem} for
scenario~$\xi(\omega)$, and let $z(\bar{x}(\xi(\omega)), \xi(\omega))$ be its
objective value. The so-called \emph{wait-and-see} (WS) solution is given by:

\begin{equation}
	WS = \mathbb{E}_{\xi} \left[ z(\bar{x}(\xi), \xi) \right].
	\label{eq:ws}
\end{equation}

That is, for each scenario $\xi(\omega)$, we solve~\eqref{eq:scenario_problem}
to optimality and take the expected value of the objective over all $\omega \in
	\Omega$. The \gls{rp}, defined by~\eqref{eq:rp} or~\eqref{eq:rp_det}, can be
written as:

\begin{equation}
	RP = \max_{x} \mathbb{E}_{\xi} \left[ z(x, \xi) \right].
	\label{eq:rp_exp}
\end{equation}
By definition, the \gls{evpi} is the difference between the wait-and-see and
here-and-now solutions:
\[
	EVPI = WS - RP.
\]

\subsection{Value of the Stochastic Solution}

A practical difficulty of the wait-and-see approach is that we must solve a
subproblem for each scenario~$\xi(\omega)$. A simpler approach is to replace the
random vector~$\xi$ with its expected value $\bar{\xi} = \mathbb{E}[\xi]$. This
problem is known as the \gls{evp}, or \emph{mean value
	problem}~\cite{birge:2011}. This corresponds to a simpler problem than the
recourse problem, since we only solve for a single future scenario. The
objective of the \gls{evp} is:

\begin{equation}
	EV = \max z(x, \bar{\xi}).
	\label{eq:evp}
\end{equation}

Let $\bar{x}(\bar{\xi})$ be an optimal solution to~\eqref{eq:evp}. Given the
stochastic nature of the problem, in general $\bar{x}(\bar{\xi})$ may not be
close to the optimal solution of the recourse problem~\eqref{eq:rp}. However,
this solution is useful for defining the \gls{vss}, which measures the quality
of the solution in terms of~\eqref{eq:rp}. We define the expected value of the
\gls{evp} solution as:

\begin{equation}
	EEV = \mathbb{E}_{\xi} \left[ z(\bar{x}(\bar{\xi}), \xi) \right].
	\label{eq:eev}
\end{equation}

This is equivalent to solving the recourse problem while fixing the first-stage
decision obtained from the \gls{evp}. Given the EEV, the \gls{vss} is:
\[
	VSS = RP - EEV,
\]
which indicates the loss incurred by adopting only the expected scenario
$\bar{\xi}$ compared to the full recourse problem~\eqref{eq:rp}. This
corresponds to the cost of ignoring uncertainty. The values $WS$~\eqref{eq:ws},
$RP$~\eqref{eq:rp_exp}, and $EEV$~\eqref{eq:eev} satisfy:
\[
	EEV \leq RP \leq WS.
\]
Thus, for a maximization problem, EEV  and wait-and-see serve, respectively, as
lower and upper bounds for the problem of interest, the recourse problem.

\section{Stochastic Optimization Models}\label{sec:cbrp-stochastic-models}

The stochastic version of the \gls{cbrp}, called in this work as \gls{scbrp},
computes, in the first-stage, a route to nebulize the blocks in the scenario $0$
(present), in which the objective is to maximize the profit considering a bonus
related to the impact on the reduction of future cases for each scenario in the
second-stage. The second-stage represents a set of independent routes that
nebulize independent blocks in each future scenario. 

In addition to the deterministic data, a set of $k$ future scenarios $\Omega =
	\{\omega_1, \dots, \omega_k\}$, with $\xi^{\omega}$ being the probability of
scenario $\omega \in \Omega$ to occur. The profit of block $b$ in the
present is $p_{b}^{0}$, and the profit in each future scenario is
$p_{b}^{\omega}$. This value represents the number of cases predicted for
that city block in the scenario $\omega$. However, the profit of each block
is affected by the first-stage, with a parameter $\alpha$ being a reduction
factor in the number of cases in a block nebulized in the first-stage. For
example, if $\alpha = 1$, then for all block $\{b \in B: y_{b}^{0} = 1\}$
will have a $0$ profit in all second-stage scenarios.

Let $\Omega' = \{0, \omega_1, \dots, \omega_k\}$ be the augmented set of
scenarios, with $0$ representing the present scenario and $\omega_1, \dots,
	\omega_k$ representing the $k$ future scenarios. The following binary decision
variables are introduced for the \gls{scbrp} model:

\begin{itemize}
	\item $y_{b}^{\omega} \in \{0, 1\}$: binary variable valued as 1 if the block $b \in B$ is nebulized in the scenario $\omega \in \Omega'$ ($y_{b}^{\omega} = 1$) or not ($y_{b}^{\omega} = 0$).
	\item $x_{a}^{\omega} \in \{0, 1\}$: binary variable valued as 1 if the arc $a \in A'$ is used in the route in the scenario $\omega \in \Omega'$ ($x_{a}^{\omega} = 1$) or not ($x_{a}^{\omega} = 0$).
	\item $z_{b}^{\omega} \in \mathbb{R}$: real variable that represents the maximum profit of a block $b \in B$ in a scenario $\omega \in \Omega'$ ($z_{b}^{\omega} \in \mathbb{R}_{+}$).
\end{itemize}

The \gls{scbrp} formulation is defined as follows:

\begin{align}
	\text{(Path-SCBRP)} & \max \overbrace{\sum_{b \in B} y_{b}^{0}(p_{b}^{0} + \alpha \sum_{\omega \in \Omega} \xi^{\omega} p_{b}^{\omega})}^{\text{First-Stage}} + \overbrace{\sum_{\omega \in \Omega} \xi^{\omega} \sum_{b \in B} z_{b}^{\omega}}^{\text{Second-Stage}} & \label{eq:sof}
\end{align}
\begin{align}
	\nonumber \text{subject to:} &                                                                                                         &                                                                                     \\
	                             & z_{b}^{\omega} \leq y_{b}^{\omega}((1 - \alpha)p_{b}^{\omega}) + (1 - y_{b}^{0})(\alpha p_{b}^{\omega}) & \forall b \in B, \omega \in \Omega \label{eq:stochastic-z-value}                    \\
	                             & z_{b}^{\omega} \leq y_{b}^{\omega}p_{b}^{\omega}                                                        & \forall b \in B, \omega \in \Omega \label{eq:stochastic-z-y-value}                  \\
	                             & \sum_{i \in V} x_{0,i}^{\omega} = \sum_{j \in V} x_{j,0}^{\omega} = 1                                   & \forall \omega \in \Omega' \label{eq:stochastic-s-t-all}                            \\
	                             & \sum_{i \in V} x_{i,j}^{\omega} - \sum_{k \in V} x_{j,k}^{\omega} = 0                                   & \forall j \in V, \omega \in \Omega' \label{eq:stochastic-flow-conservation}         \\
	                             & \sum_{j \in \delta^{-}(i)} x_{i,j}^{\omega} \geq y_{b}^{\omega}                                         & \forall b \in B, i \in V(b), \omega \in \Omega' \label{eq:stochastic-in-path}       \\
	                             & \sum_{(i, j) \in A} x_{i,j}^{\omega}t_{i,j} + \sum_{b \in B} y_{b}^{\omega}t^{'}_{b} \leq T             & \forall \omega \in \Omega' \label{eq:stochastic-max-time}                           \\
	                             & \sum_{(i, j) \in A(C)} x_{i,j}^{\omega} \leq |V(C)| - 1                                                 & \forall C \subseteq V, \omega \in \Omega' \label{eq:stochastic-subtour-elimination} \\
	                             & x \in \mathbb{B}^{|A'| * |\Omega'|}                                                                     & \label{eq:stochastic-dom-x}                                                         \\
	                             & y \in \mathbb{B}^{|B| * |\Omega'|}                                                                      & \label{eq:stochastic-dom-y}                                                         \\
	                             & z \in \mathbb{R}_{+}^{|B| * |\Omega|}                                                                   & \label{eq:stochastic-dom-z}
\end{align}

The objective function~\eqref{eq:sof} maximizes the total profit. When a block
is attended in the first-stage, the final value is the profit of the block in
scenario $0$ plus $\alpha$ times the profit for all scenarios multiplied by the
probability of the scenario $\omega$ to occur. Besides the profit associated in
first-stage, the second-stage maximizes the profit for the residual number of
cases (after the $\alpha$ reduction for apply the route in scenario $0$) in each
block and for every future scenario $\omega \in \Omega$.

Constraints~\eqref{eq:stochastic-z-value} ensure that the profit of a block $b$
in the scenario $\omega$ is $(1 - \alpha) p_{b}^{\omega}$, if $y_{b}^{0} = 1$ or
$p_{b}^{\omega}$ when $y_{b}^{0} = 0$.
Constraints~\eqref{eq:stochastic-z-y-value}  guarantee that the value of
$z_{b}^{\omega}$ is $0$ when $y_{b}^{\omega} = 0$ and $p_{b}^{\omega}$
otherwise. The Constraints from~\eqref{eq:stochastic-s-t-all}
to~\eqref{eq:stochastic-subtour-elimination} are the same as the constraints
from~\eqref{eq:s-t-all} to~\eqref{eq:circuit-subtour-elimination} of the
Path-CBRP formulation, but for independent routes for all scenario $\omega \in
	\Omega'$. Constraints~\eqref{eq:stochastic-dom-x}-\eqref{eq:stochastic-dom-z}
define the domain of the decision variables.

Considering the Path-SCBRP formulation, with the changes to consider the
stochastic nature of the problem, it is also possible to adapt the deterministic
models from Section~\ref{sec:cbrp-deterministic-models} to generate feasible
solutions for the \gls{scbrp}, i.e., creating the $k$ routes to nebulize the
blocks in the scenario $0$ and each future scenario. The further references for
the \gls{scbrp} will follow the same pattern presented for the deterministic
formulations: Path-SCBRP, Path-SCBRP-MTZ, Walk-SCBRP and Walk-SCBRP-MTZ.

\section{Multi-Agent-Based Simulation}\label{sec:multi-agent-simulation}

Epidemiological models aim to answer how a certain disease spreads in a region
and how it may appear in regions not initially considered susceptible. Since
simulation models have limitations regarding the real world, they commonly
attempt to represent a phenomenon either at a global (macro) or local (micro)
scale.

Macro-simulation is a deterministic approach that focuses on representation at a
global level, neglecting individual characteristics such as sex, age, address,
and interactions between individuals. Although easy to interpret and implement,
when using a macro model, one must be aware of these limitations since certain
individual characteristics may be crucial to disease
propagation~\citep{damien:2017}. On the other hand, micro-simulation models
contain a particular representation for each individual.

Multi-agent systems commonly represent complex systems with characteristics such
as non-linearity and multiple levels of abstraction~\citep{furtado:2015}. This
system contains agents that perceive and act on the environment, reacting to
situations and making decisions based on cognitive abilities. Typically,
predicting the global behavior of \gls{mabs} is impractical because individual
interactions between agents lead to emergent global structures.

\gls{mabs} encompass various types tailored to simulate complex systems where
multiple autonomous entities interact dynamically. One prevalent type is
task-based \gls{mabs}, focusing on agents completing specific tasks or goals
within a system. These simulations are crucial in studying decentralized systems
like logistics and manufacturing.

Furthermore, spatial \gls{mabs} integrates geographic information and spatial
relationships, essential for modeling urban planning, environmental systems, and
epidemiology. Adaptive \gls{mabs} introduces agents capable of learning and
adapting behaviors over time, necessary for studying adaptive systems such as
artificial intelligence and robotics. Lastly, hybrid \gls{mabs} combines
features from multiple types, offering versatility to model various real-world
phenomena across domains like economics, biology, and engineering. Each kind of
\gls{mabs} contributes uniquely to understanding complex systems and addressing
challenges in predictive modeling and policy analysis~\citep{Bonabeau:2002}.

Due to the inherent non-deterministic nature of \gls{mabs}, multiple simulation
runs are required to achieve statistically significant results and accurately
characterize system behavior. The complex interactions between input parameters
and output behaviors in MABS often make it challenging to establish explicit
relationships and formally validate models. To overcome this, researchers
frequently employ expert validation, as seen
in~\cite{amouroux:2008,damien:2017}, where epidemiological experts were
consulted to evaluate the model's realism and reliability.

Regardless of the scale, it is possible to use compartmental theory, where the
main idea is to represent the states of individuals~\citep{brauer-2008}. In our
Dengue spread simulation, we adopted the following states: susceptible (S),
exposed or latent (E), infected (I), and recovered (R) as illustrated in
Figure~\ref{fig:dynamicmodel}. Individuals who have never been exposed to the
disease are in state S. If an individual carries the virus but does not yet
transmit it or show symptoms, they are in state E. Symptoms appear when they
reach state I, which also allows the individual to transmit the infection. In
the R state, individuals are considered cured and immune to new infections.

\begin{figure}[!ht]
	\centering
	
	\resizebox{0.75\columnwidth}{!}{
		\tikzset{every picture/.style={line width=0.75pt}} %set default line width to
	
	\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
		%uncomment if require: \path (0,300); %set diagram left start at 0, and has
		%height of 300
		
		%Rounded Rect [id:dp9217887491174969] 
		\draw  [color={rgb, 255:red, 99; green, 171; blue, 21 }  ,draw opacity=1 ]
		(62.33,41.47) .. controls (62.33,37.34) and (65.68,34) .. (69.8,34) --
		(136.87,34) .. controls (140.99,34) and (144.33,37.34) .. (144.33,41.47) --
		(144.33,63.87) .. controls (144.33,67.99) and (140.99,71.33) .. (136.87,71.33)
		-- (69.8,71.33) .. controls (65.68,71.33) and (62.33,67.99) .. (62.33,63.87) --
		cycle ;
		%Rounded Rect [id:dp36097559929859013] 
		\draw  [color={rgb, 255:red, 208; green, 2; blue, 27 }  ,draw opacity=1 ]
		(291.67,42.13) .. controls (291.67,38.01) and (295.01,34.67) .. (299.13,34.67)
		-- (366.2,34.67) .. controls (370.32,34.67) and (373.67,38.01) .. (373.67,42.13)
		-- (373.67,64.53) .. controls (373.67,68.66) and (370.32,72) .. (366.2,72) --
		(299.13,72) .. controls (295.01,72) and (291.67,68.66) .. (291.67,64.53) --
		cycle ;
		%Straight Lines [id:da9742211892376831] 
		\draw    (259.33,53.67) -- (289.67,53.98) ; \draw [shift={(291.67,54)}, rotate =
			180.59] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]
		(10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls
		(3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
		%Rounded Rect [id:dp37752716490425275] 
		\draw  [color={rgb, 255:red, 40; green, 108; blue, 188 }  ,draw opacity=1 ]
		(408.33,42.13) .. controls (408.33,38.01) and (411.68,34.67) .. (415.8,34.67) --
		(482.87,34.67) .. controls (486.99,34.67) and (490.33,38.01) .. (490.33,42.13)
		-- (490.33,64.53) .. controls (490.33,68.66) and (486.99,72) .. (482.87,72) --
		(415.8,72) .. controls (411.68,72) and (408.33,68.66) .. (408.33,64.53) -- cycle
		;
		%Straight Lines [id:da2512507786148114] 
		\draw    (376,53.67) -- (406.33,53.98) ; \draw [shift={(408.33,54)}, rotate =
			180.59] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]
		(10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls
		(3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
		%Rounded Rect [id:dp4832950812851634] 
		\draw  [color={rgb, 255:red, 249; green, 231; blue, 9 }  ,draw opacity=0.99 ]
		(177.33,40.8) .. controls (177.33,36.68) and (180.68,33.33) .. (184.8,33.33) --
		(251.87,33.33) .. controls (255.99,33.33) and (259.33,36.68) .. (259.33,40.8) --
		(259.33,63.2) .. controls (259.33,67.32) and (255.99,70.67) .. (251.87,70.67) --
		(184.8,70.67) .. controls (180.68,70.67) and (177.33,67.32) .. (177.33,63.2) --
		cycle ;
		%Straight Lines [id:da02397316252168946] 
		\draw    (145,52.33) -- (175.33,52.65) ; \draw [shift={(177.33,52.67)}, rotate =
			180.59] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]
		(10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls
		(3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
		
		
		% Text Node
		\draw (68.33,43.33) node [anchor=north west][inner sep=0.75pt]   [align=left]
		{{\small Susceptible}};
		% Text Node
		\draw (300.67,44) node [anchor=north west][inner sep=0.75pt]   [align=left]
		{Infected};
		% Text Node
		\draw (412.33,44) node [anchor=north west][inner sep=0.75pt]   [align=left]
		{Recovered};
		% Text Node
		\draw (266,34.07) node [anchor=north west][inner sep=0.75pt]    {$\beta $};
		% Text Node
		\draw (383.33,31.07) node [anchor=north west][inner sep=0.75pt]    {$\gamma $};
		% Text Node
		\draw (187.33,42.67) node [anchor=north west][inner sep=0.75pt]   [align=left]
		{Exposed};
		% Text Node
		\draw (152.33,29.73) node [anchor=north west][inner sep=0.75pt]    {$\sigma $};
		% Text Node
		\draw (20.67,44.33) node [anchor=north west][inner sep=0.75pt]   [align=left]
		{SEIR};
		
		
	\end{tikzpicture}
	
	} \caption{Diagram of a dynamic compartmental model.}
	\label{fig:dynamicmodel}
\end{figure}

The compartment flow is based on the order of the letters~\citep{amaku:2014}.
For example, an SEIR model states that individuals are initially susceptible to
the virus or disease, then they become exposed, infected, and finally recover.
The transition between states is not mandatory and depends on the model's
internal parameters, which aim to be as coherent as possible with reality. The
choice of a model depends primarily on the intrinsic characteristics of the
disease. The literature has proposed a set of different models considering
various types of compartments, such as \textbf{SEI}~\cite{Scoglio2021,
	Puntipa2023}, \textbf{SEIR}~\cite{Scoglio2021, Puntipa2023, Meng2023,
	da-silva:2020}, and \textbf{SIR}~\cite{Umar2022, Prasetyo2023, Srivastav2023},
among others.  Classical mathematical models are mainly based on compartmental
theory, and a system of \gls{ode} describes the changes between
states~\citep{da-silva:2020}.

\section{Simheuristics}\label{sec:simheuristics}

Simulation methods are widely used to analyze complex real-life systems under
uncertainty, which is typically modeled through probability
distributions~\cite{lucas:2015}. These techniques are applied in diverse domains
such as manufacturing, logistics, transportation, healthcare, finance, smart
cities, and telecommunications. While simulation provides valuable insights into
system performance under different scenarios, it does not inherently offer
optimization capabilities, especially for large-scale and NP-hard
\gls{scop}~\cite{juan:2022}. To address this, simulation is often combined with
metaheuristics, which can efficiently explore large solution spaces and deliver
high-quality solutions in reasonable computational times.

The hybridization of simulation and optimization, known as
simulation-optimization, encompasses various methods including mathematical
programming, metaheuristics, and machine learning. In such approaches,
simulation can serve multiple roles: evaluating objective functions or
constraints in stochastic settings, generating feasible solutions, or enhancing
analytical models~\cite{juan:2015}. Surrogate models derived from simulation
outputs can further accelerate the optimization process. This integration
enables a balance between modeling realism and computational tractability,
making simulation-optimization a first-choice strategy for tackling complex
stochastic problems~\cite{juan:2022}.

Given a deterministic optimization problem, it is reasonable to assume that its
optimal and near-optimal solutions will exhibit satisfactory performance when
moderate levels of uncertainty are introduced~\cite{juan:2022}. Formally, for a
solution $s$, let $\text{det}(s)$ denote its deterministic performance and
$\text{stoch}(s)$ its stochastic performance (estimated via simulation). Under
moderate uncertainty, these values are expected to be strongly and positively
correlated. However, this correlation diminishes as uncertainty increases, and
for large variances, robust or reliable solutions may be preferable to those
merely maximizing expected performance.

Another important observation concerns the use of the best deterministic
solution $\text{det}(s^*)$. In many optimization problems, the optimal objective
value degrades as uncertainty increases, particularly when asymmetric effects
are present, where detrimental realizations of random variables outweigh
beneficial ones. Let $s^*$ denote an optimal or near-optimal deterministic
solution, and $s^{**}$ an optimal or near-optimal stochastic solution. Then, for
minimization problems, it often holds that $\text{det}(s^*) \leq
	\text{stoch}(s^{**}) \leq \text{stoch}(s^*)$, while for maximization problems,
$\text{stoch}(s^*) \leq \text{stoch}(s^{**}) \leq \text{det}(s^*)$. Thus,
deterministic optimal values provide natural lower and upper bounds for their
stochastic counterparts~\cite{juan:2022}.

\Cref{fig:logic-simheuristics} shows the default logic behind simheuristic
concept. Given a stochastic optimization problem, its deterministic counterpart
is considered. This can be done, for instance, by replacing all random variables
by their expected values, which leads to a simplified version of the stochastic
problem in which uncertainty is not considered. Then, a metaheuristic component
is employed to efficiently search inside the solution space, thus generating
increasingly better solutions to the deterministic version of the problem. Each
time the metaheuristic generates a ``promising'' solution (i.e., one that is
likely to perform well in a scenario under uncertainty), this solution is sent
to the simulation component in order to assess its performance in the stochastic
environment. 

The simulation component returns not only estimates of statistics, such as the
mean, variance, and percentiles associated with the proposed solution, but also
probabilistic information that can be useful in risk or reliability analyses, as
well as information about the status of different system variables. Since
simulation is a time consuming procedure, it is usually a good idea to employ a
short number of simulation runs every time a new promising solution is evaluated
at this stage, otherwise the simulation computing time might jeopardize the time
required by the metaheuristic to converge to near-optimal solutions.  Some
useful recommendations to speed up these computations can be found in
Rabe~\cite{rabe:2020}. 

The feedback provided by the simulation can then be processed by a machine
learning component and then used to: (i) update and adjust the metaheuristic
parameters to better explore the solution space and increase the chances of
obtaining new solutions with a high stochastic performance; (ii) build a
classification or prediction model able to identify new promising solutions with
a high accuracy, thus avoiding wasting time in simulating solutions that will
offer sub-optimal values under uncertainty conditions; and (iii) develop a
surrogate model that, at least partially, substitutes time-consuming simulations
when estimating the value of the stochastic objective function or probabilistic
constraints associated with a new promising solution proposed by the
metaheuristic component

As a result of this first stage, a reduced list of ``elite'' solutions is
obtained. According to our initial estimates, each of these solutions show a
high performance in a scenario under uncertainty. Now, in order to increase the
accuracy of our estimates, a more intensive simulation is executed on each of
the elite solutions. Of course, variance reduction techniques, such as the use
of common random numbers, can be employed here to speed up these simulations,
which can also be run in parallel processors. As a final stage, the simulation
outcomes might be employed to perform a risk or reliability analysis on each of
these elite solutions. This analysis might enrich the decision-making process
with detailed probabilistic information describing the stochastic behavior of
each elite solution.

\begin{figure}[h!]
	\centering
	\begin{tikzpicture}
		[
			node distance=1.9cm, % distance between nodes
			font=\tiny,
			align=center
		]
		
		% Defining styles
		\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm, text centered, draw=black, text width=3cm, fill=blue!30!white]
		
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		
		\tikzstyle{io} = [ellipse, minimum width=2cm, text width=2cm, minimum height=1cm, text centered, draw=black, fill=gray!30!white, font=\bf\tiny]
		
		\tikzstyle{process} = [tape, minimum width=1.5cm, text width=2cm, minimum height=1cm, text centered, draw=black, fill=green!30!white, font=\bf\tiny]
		
		\tikzstyle{decision} = [diamond, text width=1.5cm, aspect=2, text height=1, text centered, draw=black, fill=yellow!30!white, font=\bf\tiny]
		
		\tikzstyle{stage} = [rectangle, minimum width=1cm, text width=1cm, minimum height=1cm, draw=black, font=\bf\tiny]
		
		\tikzstyle{artificial} = [rectangle, draw=white, font=\bf\tiny]
		
		\tikzstyle{arrow} = [thick,->,>=stealth]
		
		% Create states
		\node (start) [startstop] at (0, 0) {Stochastic\\Optimization\\Problem};
		
		\node (deterministic) [startstop, right of=start, xshift=7cm] {Deterministic\\Optimization\\Problem};
		
		% Links
		\draw [arrow] (start) -- node[text width=3cm, fill=white, align=center] {Replacement of Random Elements} (deterministic);
		
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Stage 1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\node (metaheuristic) [process, below of=deterministic] {Metaheuristic Algorithm};
		
		\node (deterministic-sol) [io, below of=metaheuristic] {New Deterministic Solution};
		\node (ml-component) [process, below of=deterministic-sol] {Machine Learning Component};
		\node (fast-sim-component) [process, below of=ml-component] {Fast Simulation Component};
		
		\node (promissing-sol) [decision, xshift=-2.5cm, left of=ml-component] {Promissing\\Solution?};
		\node (surrogate-sol) [decision, xshift=-2.5cm, left of=fast-sim-component] {Surrogate\\Model\\Available?};
		
		\node (surrogate-component) [process, below of=surrogate-sol] {Surrogate Model};
		
		\node (update-sol-list) [io, below of=surrogate-component] {Update Solution List};
		
		\node (available-time) [decision, xshift=-2.5cm, left of=update-sol-list] {Available\\Computation\\Time?};
		
		% Links
		\draw [arrow] (deterministic) -- (metaheuristic);
		\draw [arrow] (metaheuristic) -- (deterministic-sol);
		\draw [arrow] (deterministic-sol) -- (ml-component);
		
		\draw [arrow] (ml-component) -- (promissing-sol);
		\draw [arrow] (promissing-sol) -- node[anchor=east] {yes} (surrogate-sol);
		\draw [arrow] (promissing-sol) -| node[anchor=south,xshift=2.5cm] {no} (available-time);
		
		%
		\draw [arrow] (surrogate-sol) -- node[anchor=east] {yes} (surrogate-component);
		\draw [arrow] (surrogate-sol) -- node[anchor=north] {no} (fast-sim-component);
		
		%
		\draw [arrow] (surrogate-component) -- (update-sol-list);
		\draw [arrow] (update-sol-list) -- (available-time);
		
		% 
		\draw [arrow] (available-time.west) |- node[anchor=west, yshift=-8.5cm] {yes} (metaheuristic);
		
		% Feedback
		\node (art1) [artificial, right of=metaheuristic, xshift=0.5cm] {};
		
		\draw [arrow,dashed,-] (metaheuristic) -- (art1.center);
		\draw [arrow,dashed] (art1.center) |- node[text width=1cm, fill=white, align=center, rotate=270, xshift=-1.8cm] {Feedback} (ml-component.north east);
		
		% 
		\node (art2) [artificial, right of=ml-component, xshift=0.5cm] {};
		
		\draw [arrow,dashed,-] (ml-component.east) -- (art2.center);
		\draw [arrow,dashed] (art2.center) |- node[text width=1cm, fill=white, align=center, rotate=270, xshift=-1.9cm] {Feedback} (surrogate-component);
		
		% 
		\node (art3) [artificial, right of=fast-sim-component] {};
		
		\draw [arrow,dashed,-] (fast-sim-component.east) -- (art3.center);
		\draw [arrow,dashed] (art3.center) |- node[text width=1cm, fill=white, align=center, rotate=270, xshift=0.8cm] {Feedback} (ml-component.south east);
		
		\node (stage1) [stage, fit=(art1.east) (update-sol-list) (available-time) (deterministic-sol) (start.south west), yshift=-0.5cm] {};
		\node (art4) [artificial, left of=stage1, rotate=90, yshift=5.5cm] {Stage 1};
		
		% Second Stage
		\node (elite-sol) [io, below of=available-time, yshift=-0.75cm] {Elite Stochastic Solutions};
		\node (intensive-sim-component) [process, below of=update-sol-list, yshift=-0.75cm] {Intensive Simulation Component};
		
		\draw [arrow] (available-time) -- node[anchor=east, yshift=0.5cm] {no} (elite-sol);
		\draw [arrow] (elite-sol) -- (intensive-sim-component);
		
		\node (art5) [artificial, left of=elite-sol, below of=available-time, xshift=0.3cm] {};
		\node (art6) [artificial, right of=intensive-sim-component, below of=intensive-sim-component, yshift=1.25cm, xshift=4.9cm] {};
		
		\node (stage2) [stage, fit=(art5) (art6)] {};
		\node (art7) [artificial, left of=stage2, rotate=90, yshift=5.5cm] {Stage 2};
		
		% Third stage
		\node (risk-component) [process, below of=intensive-sim-component, yshift=-0.25cm] {Risk/Reliability\\Component};
		\draw [arrow] (intensive-sim-component) -- (risk-component);
		
		\node (art8) [artificial, left of=risk-component, below of=elite-sol, xshift=0.3cm, yshift=0.55cm] {};
		\node (art9) [artificial, right of=risk-component, below of=risk-component, yshift=1.25cm, xshift=4.9cm] {};
		
		\node (stage3) [stage, fit=(art8) (art9)] {};
		\node (art10) [artificial, left of=stage3, rotate=90, yshift=5.5cm] {Stage 3};
		
		% Final
		\node (elite-stochastic-sol) [io, below of=risk-component, yshift=-0.5cm] {Elite Stochastic\\Solutions with Probabilistic Information};
		
		\draw [arrow] (risk-component) -- (elite-stochastic-sol);
	\end{tikzpicture}
	\caption{Logic Behind Simheuristics \cite{juan:2022}.}
	\label{fig:logic-simheuristics}
\end{figure}