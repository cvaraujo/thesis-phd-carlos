\chapter{Methodologies}\label{chap:methodologies}

This section presents the methodologies applied to solve the \gls{cbrp} in its deterministic
and stochastic versions (\gls{scbrp}),
to simulate the spread of the Dengue virus, to develop a simulation-optimization framework
and for the statistical analysis of the results.

\section{Lagrangean Relaxations}\label{sec:lagrangean-relaxations}

\newcommand{\mult}[2]{\ensuremath{\lambda^{#1}_{#2}}}
\newcommand{\lrsp}{\textit{LR-SP}}
\newcommand{\lrkn}{\textit{LR-KN}}
\newcommand{\lrcsp}{\textit{LR-RCSP}}
\newcommand{\lrcspkn}{\textit{LR-RCSP-KN}}

This section presents the \gls{lr} obtained from the formulation Walk-CBRP, presented in
Section~\ref{sec:cbrp-walk-based-formulation}.
The Lagrange multipliers are represented by $\lambda$'s,
then~\mult{\ref{eq:walk-in-path}}{} and
\mult{\ref{eq:walk-max-time}}{} are
the non-negative variables  associated with the constraints~\eqref{eq:walk-in-path},
\eqref{eq:walk-max-time}, respectively. All  the relaxations have as their
\gls{lpp}, the \gls{kn}, \gls{sp} or the \gls{rcsp} subproblems.
The nomenclature used for each relaxation  follows the \gls{lr}-X pattern, where ``X''
represents one of the most difficult subproblems of the \gls{lpp} being solved.

\subsection{Lagrangean Relaxation with Shortest Path}\label{sec:lr-sp}

The \gls{lr} resulting from the dualization of the constraints~\eqref{eq:walk-in-path}
and~\eqref{eq:walk-max-time}
is very close to the problem of computing \gls{sp}s and is therefore called {\lrsp}.
The constraints~\eqref{eq:walk-s-t-all}-\eqref{eq:walk-flow-conservation}
and~\eqref{eq:walk-subtour-elimination}-\eqref{eq:walk-dom-y} model a problem similar
to create a path going from the depot $s = 0$ through the nodes of $V$ and going back to $s$,
using the variables $x_{ij}$ for all $i, j \in V, i \neq j$. As the \gls{lpp} contains no
constraint that apply to the variables $y_{b}$, the subproblem associated with these variables
consists in selecting the blocks $b \in B$ with the highest value  according to the lagrangian costs.
When the constraints~\eqref{eq:walk-in-path} and~\eqref{eq:walk-max-time}
are dualized, the resulting \gls{lpp} is:

\begin{align}
	\text{(LR-SP)}                                                                                                                                                \max \sum_{b \in B} p_{b} y_{b} + \mult{\ref{eq:walk-max-time}}{}
	(T - (\sum_{a \in A} x_{i,j}t_{i,j} + \sum_{b \in B} y_b t_b))                                                                                                & \label{eq:lrsp-of}   \\
	\nonumber                                                                                                                                                     + \sum_{b \in B} \mult{\ref{eq:walk-in-path}}{b}
	(\sum_{i \in V(b)} \sum_{a \in \delta^{-}(i)}x_{i,j} - y_b)                                                                                                   &                    & \\
	\nonumber \text{subject to: } \eqref{eq:walk-s-t-all}-\eqref{eq:walk-flow-conservation}\text{ and } \eqref{eq:walk-subtour-elimination}-\eqref{eq:walk-dom-y} &                    &
\end{align}


Thus, rearranging the terms, splitting into variables and inverting the signal in the X
term we have to solve the following optimization problems:
\begin{align}
	\text{(Y)}         & \max \sum_{b \in B} y_{b} (p_b - \mult{\ref{eq:walk-in-path}}{b} - \mult{\ref{eq:walk-max-time}}{} t_b) +                                                            \\
	\text{(X)}         & \max \sum_{(i,j) \in A} x_{i,j} \mult{\ref{eq:walk-max-time}}{} t_{i,j} - \sum_{b \in B} \sum_{(i,j) \in \delta^{+}(V(b))} x_{i,j} \mult{\ref{eq:walk-in-path}}{b} + \\
	\text{(constants)} & \mult{\ref{eq:walk-max-time}}{} T
\end{align}

Two approaches were used to solve {\lrsp}:  the first solution strategy is to use
an \gls{ilp}  solver to obtain  solutions in  each iteration of  the subgradient
method;  the  second  approach  is  to solve  the  \gls{lpp}  subproblems  using
combinatorial  algorithms.  A factor  that  influences  the complexity  of
solving  the  \gls{sp}  problem  is  related  to  the  possibility  of  negative
coefficients associated  with the variables  $x_{i,j}$ as consequence  of the
dualization of constraint~\eqref{eq:walk-max-time}.  Indeed, when  computing a
\gls{sp} the returned  solution may contain negative cycles, and  to avoid these
situations we define other variations of {\lrsp} by increasing the difficulty
of the subproblem adding time constraints.

\subsection{Lagrangean Relaxations with Time Constraints}\label{sec:lr-time-constraints}

Since the time constraint \eqref{eq:walk-max-time} is dualized and the resulting
\gls{lpp} is a \gls{sp} problem for variables $x_{i,j}$ and a selection problem for variables $y_b$,
we can define other variations of {\lrsp} by increasing the difficulty of the subproblem.
Thus, we increase the formulation Walk-CBRP by adding two new constraints that are redundant:
\begin{align}
	\sum_{(i,j) \in A} x_{i,j}t_{i,j} \leq T & \label{eq:arc-time-constraints}   \\
	\sum_{b \in B} y_b t_b \leq T            & \label{eq:block-time-constraints}
\end{align}

Thus, the resulting \gls{lpp}, referred as {\lrcsp}, is the variation of {\lrsp} with the addition of
Constraint~\eqref{eq:arc-time-constraints}.
The most difficult subproblem in the \gls{lpp} passes from a \gls{sp} problem to a
\gls{sp} problem with resource constraints, known as \gls{rcsp}. Since the amount
of time spent on the arcs is limited, the presence of negative costs not generate
a negative cycle that makes the subproblem infeasible. Computing  \gls{rcsp} is NP-hard,
however there are  exact algorithms that are efficient to  solve this problem in
practice~\cite{irnich:2006}. Our  implementations use  the labeling  algorithm
available  in   the  Boost  C++  Library~\cite{boost:2020}.

If the constraint~\eqref{eq:arc-time-constraints} is replaced by
the constraint~\eqref{eq:block-time-constraints}, the resulting \gls{lpp} will be referred as {\lrkn}.
The difficult subproblem in the \gls{lpp} now is associated with the variables $y_b$, that changes
from a selection problem to a \gls{kn} problem~\cite{karp:1972}. Computing a solution for the \gls{kn} problem
is NP-hard~\cite{korte:2008}, however there are exact algorithms based on dynamic programming that are
efficient to solve this problem in practice.

The most difficult version of this set of \gls{lrs} is {\lrcspkn}, tha uses both
constraints~\eqref{eq:arc-time-constraints} and~\eqref{eq:block-time-constraints}.
The resulting subproblems in the \gls{lpp} are \gls{kn} and \gls{rcsp} problems.
This relaxation is the expensive one in terms of computational demand.

\section{Deterministic \gls{cbrp} Heuristic}\label{sec:deterministic-heuristics}

This section present the heuristic approaches to solve the \gls{cbrp} in its deterministic version. The constructive heuristic of section~\ref{sec:greedy-constructive-algorithm} is a generic approach that can be used to solve the \gls{cbrp} also in its stochastic version.

\newcommand{\Call}[2]{\textit{#1}(#2)}

\subsection{Greedy Constructive Algorithm}\label{sec:greedy-constructive-algorithm}

The Greedy Constructive algorithm combines a binary search strategy to determine a high-quality time allocation with a \gls{kn}-based block selection and a heuristic routing method based on shortest paths in a \gls{dag}. The algorithm operates within three main steps: initially selects blocks to attend maximizing the profit per block, then defines a sequence for visiting all blocks of the previous step and, finally, create a route connecting those blocks in the selected order and check if it is feasible within the total time constraint.

\begin{algorithm}[h!]
	\caption{Greedy Constructive Algorithm} \label{alg:greedy-constructive-algorithm}
	\SetAlgoLined
	\KwData{Graph $G$, time limit $T$}
	\KwResult{Solution with objective value $OF$, attended blocks $y$ and route $x$}

	\tcp{Initialization}
	$B \leftarrow$ number of blocks\;
	$y \leftarrow$ empty vector of blocks\;
	$x \leftarrow$ empty vector of arcs\;
	$OF \leftarrow 0$\;

	\tcp{Block Selection}
	\For{$i = 1$ \textbf{to} $B$}{
	$blocks[i] \leftarrow i$\;
	$time[i] \leftarrow$ time to attend block $i$\;
	$p_b[i] \leftarrow$ profit of block $i$\;
	}

	$OF \leftarrow$ \Call{SolveScenario}{$p_b$, $time$, $T$, $y$}\;

	\Return{$(OF, y, x)$}\;
\end{algorithm}

The SolveScenario routine implements a binary search strategy to find a good allocation of time between block attendance and routing. The algorithm starts by initializing the binary search bounds, with the lower bound $lb$ set to $0.5$ and upper bound $ub$ set to $1.0$, representing the fraction of total time $T$ that can be allocated to block attendance. The algorithm first attempts to find a solution using the full time budget $T$ by calling BinarySolve with $available\_time = T$. If this succeeds (returning a non-negative objective value), the algorithm immediately returns this as an optimal solution based on Property~\ref{property:knapsack-optimal-allocation}.

\begin{property}[Optimality of Knapsack Block Selection with Full Time Allocation]
	When the knapsack problem is used to select blocks with the total time budget $T$, and if the selected blocks can be connected by any feasible route respecting the time limit $T$, then the solution produced by the knapsack is optimal for the \gls{cbrp}.

	\begin{proof}
		The classical 0-1 knapsack problem maximizes the total profit
		(here, the number of cases attended) subject to a total time constraint $T$. The greedy heuristic first solves this knapsack problem to select a subset of blocks whose total time does not exceed $T$ and whose total profit is maximized. If, after this selection, exist at least one possible route to connect the selected blocks within the total time respecting the limit $T$, then there are no additional constraints beyond the knapsack constraint. Therefore, the solution found by the knapsack is not only feasible but also optimal for the \gls{cbrp}, as no other selection of blocks can yield a higher profit without exceeding the time limit. Thus, under the assumption of feasible routing, the knapsack solution is optimal.
	\end{proof}
	\label{property:knapsack-optimal-allocation}
\end{property}

If the full time allocation is infeasible, then the algorithm tries a more conservative approach by allocating only $50\%$ of the total time to block attendance. If this also fails, it adjusts the search bounds by setting the upper bound to the current lower bound and the lower bound to $0.0$, effectively searching in the range $[0.0, 0.5]$. If the $50\%$ allocation succeeds, it becomes the current best solution and the search continues in the range $[0.5, 1.0]$.

The binary search loop continues until the search interval becomes sufficiently small (less than $0.001$). In each iteration, the algorithm calculates the midpoint of the current search interval and attempts to solve the problem with that time allocation. If the solution is infeasible (BinarySolve returns \textit{infeasible}), the upper bound is reduced to the current midpoint. If feasible, the solution becomes the new best solution and the lower bound is increased to the current midpoint. This process efficiently define the most profitable feasible time allocation for block attendance and routing to connect the selected blocks.

\begin{algorithm}[h!]
	\caption{SolveScenario}
	\SetAlgoLined
	\KwData{block profit $p_b$, time limit $T$}
	\KwResult{Objective value $OF$}

	$lb \leftarrow 0.5$, $ub \leftarrow 1.0$, $mid \leftarrow 0.0$\;
	$OF \leftarrow 0$, $temp\_OF \leftarrow 0$\;
	$available\_time \leftarrow T$\;

	$temp\_OF \leftarrow$ \Call{BinarySolve}{$p_b$, $available\_time$, $T$, $y$}\;
	\If{$temp\_OF \text{is not \textit{infeasible}}$}{
		\Return{$temp\_OF$}; \tcp{Optimal solution}

	}

	$available\_time \leftarrow \lfloor 0.5 \times T \rfloor$; \tcp{Lower bound solution}
	$temp\_OF \leftarrow$ \Call{BinarySolve}{$p_b$, $available\_time$, $T$, $y$}\;
	\If{$temp\_OF \text{is \textit{infeasible}}$}{
		$ub \leftarrow lb$, $lb \leftarrow 0.0$\;
	}\Else{
		$OF \leftarrow temp\_OF$\;
	}
	$mid \leftarrow \frac{(lb + ub)}{2.0}$\;

	\tcp{Binary search loop}
	\While{$ub - lb > 0.001$}{
		$available\_time \leftarrow \lfloor mid \times T \rfloor$\;
		$temp\_OF \leftarrow$ \Call{BinarySolve}{$p_b$, $available\_time$, $T$, $y$}\;
		\If{$temp\_OF = -1$}{
			$ub \leftarrow mid$\;
		}\Else{
			$OF \leftarrow temp\_OF$, $y \leftarrow temp\_y$, $lb \leftarrow mid$\;
		}
		$mid \leftarrow \frac{(lb + ub)}{2.0}$\;
	}

	\Return{$OF$}\;
\end{algorithm}

The BinarySolve routine combines \gls{kn} optimization with routing feasibility checking to determine the optimal block selection for a given reserved time. The \gls{kn} solution selects the blocks that maximize the total profit within the available time. If no blocks can be selected (empty solution), the algorithm returns \textit{infeasible}. The block connection could use a caching mechanism based on the sequence of blocks to avoid redundant computations. The HeuristicBlockConnection routine is called to generate a route connecting the selected blocks in the sequence. Finally, the algorithm performs a feasibility check by verifying if the sum of block attendance time and the connecting routing time does not exceed the total time limit $MT$. If feasible, it returns the objective value, otherwise it returns \textit{infeasible}.

\begin{algorithm}[h!]
	\caption{BinarySolve}
	\SetAlgoLined
	\KwData{Block profit $p_b$, reserved time $reserved\_time$, maximum time $MT$}
	\KwResult{Objective value $OF$}

	$OF, y \leftarrow$ \Call{KnapsackSolve}{$p_b$, $reserved\_time$, $MT$}\;
	\If{$y$ is empty}{
		\Return{\textit{infeasible}}\;
	}

	$block\_attended\_time \leftarrow 0$; \tcp{Total attendance time}
	\For{each block $b$ in $y$}{
		$block\_attended\_time \leftarrow block\_attended\_time +$ time to attend block $b$\;
	}

	$connection\_time \leftarrow$ \Call{HeuristicBlockConnection}{$G$, $y$}; \tcp{Route time}

	\If{$block\_attended\_time + connection\_time \leq MT$}{
		\Return{$OF$}; \tcp{Feasible solution}
	}
	\Return{\textit{infeasible}}\;
\end{algorithm}

The KnapsackSolve routine implements the classic 0-1 \gls{kn} problem using \gls{dp}. The problem is formulated as selecting a subset of blocks that maximizes the total profit while respecting the time constraint. The algorithm initializes a two-dimensional \gls{dp} table $dp[n+1][MT+1]$ where $dp[i][w]$ represents the maximum profit that can be achieved using the first $i$ blocks with a time capacity of $w$. The table is initialized with zeros, representing the base case where no blocks are selected.

The \gls{dp} table is filled using the standard \gls{kn} recurrence relation. For each block $i$ and time capacity $w$, the algorithm considers two options: either include block $i$ (if its time requirement fits within the remaining capacity) or exclude it. The optimal choice is the one that maximizes the total profit. The recurrence relation is: $dp[i][w] = \max(dp[i-1][w], dp[i-1][w-time[i-1]] + p_b[i-1])$ if $time[i-1] \leq w$, otherwise $dp[i][w] = dp[i-1][w]$. This ensures that each block is considered at most once and the time constraint is respected.

After filling the \gls{dp} table, the algorithm backtracks to reconstruct the actual solution. Starting from the maximum time capacity $MT$ and the last block $n$, it checks if including block $i$ contributed to the optimal solution by comparing $dp[i][w]$ with $dp[i-1][w]$. If they differ, block $i-1$ is added to the solution and the remaining capacity is reduced accordingly.

\begin{algorithm}[h!]
	\caption{KnapsackSolve}
	\SetAlgoLined
	\KwData{block profit $p_b$, reserved time $T$}
	\KwResult{Maximum profit $OF$ and selected blocks $y$}

	$n \leftarrow$ number of blocks\;
	Initialize $dp[n+1][T+1]$ with zeros\;

	\For{$i = 1$ \textbf{to} $n$}{
		\For{$w = 1$ \textbf{to} $T$}{
			\If{$time[i-1] \leq w$}{
				$dp[i][w] \leftarrow \max(dp[i-1][w], dp[i-1][w-time[i-1]] + p_b[i-1])$\;
			}\Else{
				$dp[i][w] \leftarrow dp[i-1][w]$\;
			}
		}
	}

	\tcp{Backtrack to find selected blocks}
	$w \leftarrow T$\;
	\For{$i = n$ \textbf{downto} $1$}{
		\If{$dp[i][w] \neq dp[i-1][w]$}{
			Add block $i-1$ to $y$\;
			$w \leftarrow w - time[i-1]$\;
		}
	}

	\Return{$dp[n][T]$, $y$}\;
\end{algorithm}

The Algorithm~\ref{alg:heuristic-block-connection}, HeuristicBlockConnection, solves the routing problem for visiting all selected blocks using a greedy approach. This is essentially a variant of the \gls{tsp} where the goal is to find a minimum cost route that visits at least one node from all selected blocks. The algorithm first handles the trivial case where only one block is selected. In this case, no routing is needed, so the cost is zero and the path simply goes from the depot to any node of the block and back to the depot.

Besides the sequence of blocks, the heuristic defines the route that connects those blocks and which node attends to each block. The algorithm uses an approach that variates the sequence of blocks (sorting option) and the distance considered between the blocks (the smallest shortest path between each pair of blocks or the shortest path between a specific node from the current block and a specific node of the next block). The algorithm sort the blocks to be attended according to the sorting option and the distance criteria for the greedy heuristic, then create a multi-layered \gls{dag}, that will be described in more details next in this section, to compute the shortest route that visits all blocks in $\mathcal{B}'$. The shortest route is then computed by finding the shortest path from the artificial depot $s$ to $t$ in the \gls{dag}. The route time is then calculated by summing the time of the arcs in the path and the algorithm maintains the best solution found across all the 8 combinations of $sort\_opt$ and $block\_distance\_opt$.

\begin{algorithm}[h!]
	\caption{Heuristic Block Connection}\label{alg:heuristic-block-connection}
	\SetAlgoLined
	\KwData{Graph $G$, shortest path calculator $SP$, selected blocks $blocks$}
	\KwResult{best route time $best\_time$ and route $best\_path$}

	\If{$|blocks| = 1$}{
		\Return{$0$}; \tcp{Single block}
	}
	$best\_time \leftarrow \infty$\;
	$best\_path \leftarrow$ empty\;

	\For{$block\_distance\_opt = 1$ \textbf{to} $2$}{
		\For{$sort\_opt = 1$ \textbf{to} $4$}{
			$ordered\_blocks \leftarrow$ \Call{GreedyBlockOrderingHeuristic}{$blocks$, $sort\_opt$, $block\_distance\_opt$}\;
			$G_{DAG} \leftarrow$ \Call{CreateLayeredDAG}{$ordered\_blocks$}\;
			$path \leftarrow$ \Call{ShortesPathInDAG}{$G_{DAG}(s, t)$}\;
			$time \leftarrow$ \Call{CalculateTime}{$path$}\;
			\If{$time < best\_time$}{
				$best\_time \leftarrow time$\;
				$best\_path \leftarrow path$\;
			}
		}
	}
	\Return{$best\_time$, $best\_path$}\;
\end{algorithm}

The Algorithm~\ref{alg:greedy-block-ordering-heuristic} presents a greedy heuristic that determines the order in which the blocks must be visited. Given a set of blocks $\mathcal{B} = \{b_1, b_2, \ldots, b_m\}$, a sorting option $sort\_opt$, and a block distance option $block\_distance\_opt$, the algorithm constructs an ordered sequence $\mathcal{B}' = \{b'_1, b'_2, \ldots, b'_m\}$ that iteratively minimizes the total travel distance between consecutive blocks. The parameter $sort\_opt$ contains the following options:

\begin{itemize}
	\item When $sort\_opt = 0$, blocks are sorted in ascending order by the cummulative hops of the block nodes. Hops are the number of arcs in the shortest path between a node $i \in V$ and the closest node $j \in V$ of the block $b \in B$ in the Graph $G$. The goal here is to prioritize blocks that are, in general, closer to the higher number of other blocks in the graph.
	\item When $sort\_opt = 1$, blocks are sorted in descending order by the number of nodes they contain, favoring larger blocks that offer more routing flexibility.
	\item When $sort\_opt = 2$, blocks are sorted by their count of zero-hop nodes in descending order, emphasizing blocks with high internal connectivity.
	\item When $sort\_opt = 3$, blocks are shuffled randomly.
\end{itemize}

And two options for the block distance option $block\_distance\_opt$:
\begin{itemize}
	\item When $block\_distance\_opt = \text{B2B}$, the distance between blocks is the lowest shortest path between all nodes from block $b_1$ to nodes in block $b_2$.
	\item When $block\_distance\_opt = \text{N2B}$, the distance between blocks is the shortest path between a specific node from the current block and all nodes in the next block.
\end{itemize}

Following the initial sorting, the algorithm employs a strategy to iteratively construct the block visitation sequence. The first block in the sorted list is selected as the starting point, and a reference node from this block is identified as having the minimum distance to the next unvisited block in the sorted list. In subsequent iterations, the algorithm evaluates all unvisited blocks and selects the one within the shortest path from the current reference node. When multiple blocks have equal distances, ties are broken by preferring blocks with larger numbers of nodes, as these provide greater flexibility in path construction. The reference node is then updated to the closest node in the newly selected block, and this process continues until all blocks have been used.

Given an ordered sequence of blocks $\mathcal{B} = \{b_1, b_2, \ldots, b_m\}$ to visit, the next step is to construct a multi-layered \gls{dag} where each layer $i$ corresponds to block $b_i$ and contains a new vertex for each node that belongs to the block in the original graph $G$. The formal definition of the \gls{dag} is $G_{DAG} = (V_{DAG}, A_{DAG})$ where $V_{DAG} = \{s, t\} \cup v^{b_i}_k: i \in \mathcal{B}, k \in V(b_i)$ and $A_{DAG} = \{(s, v^{b_1}_{k}), (v^{b_m}_{k'}, t): k \in V(b_1), k' \in V(b_m)\} \cup \{(v^{b_i}_o, v^{b_{i+1}}_{d}): i = 1, \ldots, m-1, o \in V(b_i), d \in V(b_{i+1})\}$.  The weight of each arc $(i, j) \in A_{DAG}$ is the shortest path distance between the nodes $i$ and $j$ in the graph $G$ Each path from $s$ to $t$ in $G_{DAG}$ include at least one node from each block in $\mathcal{B}$.

Figure~\ref{fig:layered-dag-adaptation} presents an example of the adaptation for the layered-dag. The graph $G$ in represented in Figure~\ref{subfig:original-graph}, that contains the blocks $A$, $B$ and $C$. Considering that those blocks must be visited in the order $\mathcal{B}': A \rightarrow C \rightarrow B$, the resulting graph $G_{DAG}$ is presented in Figure~\ref{subfig:layered-dag}. One possible solution is presented in Figure~\ref{subfig:layered-dag-solution}, using node $11$ to attend blocks $A$ and $C$, and node $6$ to attend block $B$. The $G_{DAG}$ solution is $s \rightarrow A_{11} \rightarrow C_{11} \rightarrow B_{6} \rightarrow t$, that could be mapped to the original graph as $s \rightarrow 11 \rightarrow 8 \rightarrow 6 \rightarrow t$. The route connecting $s$ and $t$ could be obtained by using any shortest path algorithm.

\begin{figure}[h!]
	\centering
	\begin{minipage}[c]{.45\textwidth}
		\begin{tikzpicture}[
				> = stealth, % arrow head style
				shorten > = 0.8pt, % don't touch arrow head to node
				auto,
				node distance = 2cm, % distance between nodes
				semithick % line style
			]

			\tikzstyle{every state}=[
			draw = black,
			thick,
			fill = white,
			minimum size = 8mm
			]

			\node[state] (a) at (0,0) {$1$};
			\node[state, right of = a] (b) {$2$};
			\node[state, above of = a] (c) {$3$};
			\node[state, draw = white, text=teal, below of = c, right of = a, yshift=3cm, xshift=-1cm] {A};

			\node[state, right of = b, xshift=0.1cm] (d) {$4$};

			\node[state, right of = d, xshift=0.1cm] (e) {$5$};
			\node[state, above of = d, xshift=0.1cm] (f) {$6$};
			\node[state, above of = e] (g) {$7$};
			\node[state, draw = white, text=red, above of = e, right of = f, yshift=-2.6cm, xshift=-0.6cm] {B};

			\node[state, above of = f, xshift=-0.3cm] (h) {$8$};
			\node[state, above of = h] (i) {$9$};
			\node[state, left of = i] (j) {$10$};
			\node[state, below of = j] (k) {$11$};
			\node[state, draw = white, text=green, below of = j, right of = k, yshift=3cm, xshift=-1cm] {C};

			\path[->] (a) edge node {} (c);
			\path[->] (c) edge node {} (a);

			\path[->] (k) edge node {} (b);
			\path[->] (b) edge node {} (k);

			\path[->] (k) edge node {} (c);
			\path[->] (c) edge node {} (k);

			\path[->] (b) edge node {} (a);
			\path[->] (a) edge node {} (b);

			\path[->] (b) edge node {} (d);
			\path[->] (d) edge node {} (b);

			\path[->] (d) edge node {} (e);
			\path[->] (e) edge node {} (d);

			\path[->] (e) edge node {} (f);
			\path[->] (f) edge node {} (e);

			\path[->] (f) edge node {} (g);
			\path[->] (g) edge node {} (f);

			\path[->] (g) edge node {} (e);
			\path[->] (e) edge node {} (g);

			\path[->] (h) edge node {} (k);
			\path[->] (k) edge node {} (h);

			\path[->] (k) edge node {} (j);
			\path[->] (j) edge node {} (k);

			\path[->] (j) edge node {} (i);
			\path[->] (i) edge node {} (j);

			\path[->] (i) edge node {} (h);
			\path[->] (h) edge node {} (i);

			\path[->] (f) edge node {} (h);
			\path[->] (h) edge node {} (f);

		\end{tikzpicture}
		\subcaption{\label{subfig:original-graph} Original Graph $G$.}
	\end{minipage}
	\\
	\begin{minipage}[c]{.45\textwidth}
		\begin{tikzpicture}[
				> = stealth, % arrow head style
				shorten > = 0.8pt, % don't touch arrow head to node
				auto,
				node distance = 1.5cm, % distance between nodes
				semithick % line style
			]

			\tikzstyle{every state}=[
			draw = black,
			thick,
			fill = white,
			minimum size = 11mm
			]

			\node[state, double] (s) at (0,0) {$s$};
			\node[state, right of = s, draw = white] (depot_legend) {Depot};

			\node[state, below of = s, draw = teal, xshift=-0.6cm, yshift=-0.5cm] (a2) {$A_2$};
			\node[state, left of = a2, draw = teal] (a1) {$A_1$};
			\node[state, right of = a2, draw = teal] (a3) {$A_3$};
			\node[state, right of = a3, draw = teal] (a11) {$A_{11}$};

			\node[state, below of = a1, yshift=-1cm, draw = green] (c8) {$C_8$};
			\node[state, right of = c8, draw = green] (c9) {$C_9$};
			\node[state, right of = c9, draw = green] (c10) {$C_{10}$};
			\node[state, right of = c10, draw = green] (c11) {$C_{11}$};

			\node[state, below of = c9, xshift=-0.8cm, yshift=-1cm, draw = red] (b5) {$B_5$};
			\node[state, right of = b5, draw = red] (b6) {$B_6$};
			\node[state, right of = b6, draw = red] (b7) {$B_7$};

			\node[state, double, below of = b6, yshift=-0.5cm] (t) {$t$};
			% Arcs
			\path[->, draw=black, thick] (s) edge (a1);
			\path[->, draw=black, thick] (s) edge (a2);
			\path[->, draw=black, thick] (s) edge (a3);
			\path[->, draw=black, thick] (s) edge (a11);

			\path[->, draw=black, thick] (a1) edge (c8);
			\path[->, draw=black, thick] (a1) edge (c9);
			\path[->, draw=black, thick] (a1) edge (c10);
			\path[->, draw=black, thick] (a1) edge (c11);
			\path[->, draw=black, thick] (a2) edge (c8);
			\path[->, draw=black, thick] (a2) edge (c9);
			\path[->, draw=black, thick] (a2) edge (c10);
			\path[->, draw=black, thick] (a2) edge (c11);
			\path[->, draw=black, thick] (a3) edge (c8);
			\path[->, draw=black, thick] (a3) edge (c9);
			\path[->, draw=black, thick] (a3) edge (c10);
			\path[->, draw=black, thick] (a3) edge (c11);
			\path[->, draw=black, thick] (a11) edge (c8);
			\path[->, draw=black, thick] (a11) edge (c9);
			\path[->, draw=black, thick] (a11) edge (c10);
			\path[->, draw=black, thick] (a11) edge (c11);

			\path[->, draw=black, thick] (c8) edge (b5);
			\path[->, draw=black, thick] (c8) edge (b6);
			\path[->, draw=black, thick] (c8) edge (b7);
			\path[->, draw=black, thick] (c9) edge (b5);
			\path[->, draw=black, thick] (c9) edge (b6);
			\path[->, draw=black, thick] (c9) edge (b7);
			\path[->, draw=black, thick] (c10) edge (b5);
			\path[->, draw=black, thick] (c10) edge (b6);
			\path[->, draw=black, thick] (c10) edge (b7);
			\path[->, draw=black, thick] (c11) edge (b5);
			\path[->, draw=black, thick] (c11) edge (b6);
			\path[->, draw=black, thick] (c11) edge (b7);

			\path[->, draw=black, thick] (b5) edge (t);
			\path[->, draw=black, thick] (b6) edge (t);
			\path[->, draw=black, thick] (b7) edge (t);

			% \path[->, draw = gray, opacity = 0.2] (a) edge node {} (c);
			% \path[->, draw = gray, opacity = 0.2] (c) edge node {} (b);
			% \path[->, draw = gray, opacity = 0.2] (b) edge node {} (a);

			% \path[->, draw = black, opacity = 1.0, dashed] (b) edge node {} (d);
			% \path[->, draw = black, opacity = 1.0, dashed] (d) edge node {} (e);

			% \path[->, draw = black, opacity = 1.0, dashed] (e) edge node {} (f);
			% \path[->, draw = gray, opacity = 0.2] (f) edge node {} (g);
			% \path[->, draw = gray, opacity = 0.2] (g) edge node {} (e);

			% \path[->, draw = gray, opacity = 0.2] (h) edge node {} (k);
			% \path[->, draw = gray, opacity = 0.2] (k) edge node {} (j);
			% \path[->, draw = gray, opacity = 0.2] (j) edge node {} (i);
			% \path[->, draw = gray, opacity = 0.2] (i) edge node {} (h);

			% \path[->, draw = black, opacity = 1.0, dashed] (f) edge node {} (h);
		\end{tikzpicture}
		\subcaption{\label{subfig:layered-dag} Layered DAG $G_{DAG}$.}
	\end{minipage}
	\hfill
	\begin{minipage}[c]{.45\textwidth}
		\begin{tikzpicture}[
				> = stealth, % arrow head style
				shorten > = 0.8pt, % don't touch arrow head to node
				auto,
				node distance = 1.5cm, % distance between nodes
				semithick % line style
			]

			\tikzstyle{every state}=[
			draw = black,
			thick,
			fill = white,
			minimum size = 11mm
			]

			\node[state, double] (s) at (0,0) {$s$};
			\node[state, right of = s, draw = white] (depot_legend) {Depot};

			\node[state, below of = s, draw = teal, xshift=-0.6cm, yshift=-0.5cm] (a2) {$A_2$};
			\node[state, left of = a2, draw = teal] (a1) {$A_1$};
			\node[state, right of = a2, draw = teal] (a3) {$A_3$};
			\node[state, right of = a3, draw = teal] (a11) {$A_{11}$};
			% \node[state, right of = a11, draw = white] (depot_legend) {Block A};

			\node[state, below of = a1, yshift=-1cm, draw = green] (c8) {$C_8$};
			\node[state, right of = c8, draw = green] (c9) {$C_9$};
			\node[state, right of = c9, draw = green] (c10) {$C_{10}$};
			\node[state, right of = c10, draw = green] (c11) {$C_{11}$};
			% \node[state, right of = c11, draw = white] (depot_legend) {Block C};

			\node[state, below of = c9, xshift=-0.8cm, yshift=-1cm, draw = red] (b5) {$B_5$};
			\node[state, right of = b5, draw = red] (b6) {$B_6$};
			\node[state, right of = b6, draw = red] (b7) {$B_7$};
			% \node[state, right of = b7, draw = white] (depot_legend) {Block B};

			\node[state, double, below of = b6, yshift=-0.5cm] (t) {$t$};
			% Arcs
			\path[->, draw=gray, opacity=0.2, thick] (s) edge (a1);
			\path[->, draw=gray, opacity=0.2, thick] (s) edge (a2);
			\path[->, draw=gray, opacity=0.2, thick] (s) edge (a3);
			\path[->, draw=black, thick] (s) edge (a11);

			\path[->, draw=gray, opacity=0.2, thick] (a1) edge (c8);
			\path[->, draw=gray, opacity=0.2, thick] (a1) edge (c9);
			\path[->, draw=gray, opacity=0.2, thick] (a1) edge (c10);
			\path[->, draw=gray, opacity=0.2, thick] (a1) edge (c11);
			\path[->, draw=gray, opacity=0.2, thick] (a2) edge (c8);
			\path[->, draw=gray, opacity=0.2, thick] (a2) edge (c9);
			\path[->, draw=gray, opacity=0.2, thick] (a2) edge (c10);
			\path[->, draw=gray, opacity=0.2, thick] (a2) edge (c11);
			\path[->, draw=gray, opacity=0.2, thick] (a3) edge (c8);
			\path[->, draw=gray, opacity=0.2, thick] (a3) edge (c9);
			\path[->, draw=gray, opacity=0.2, thick] (a3) edge (c10);
			\path[->, draw=gray, opacity=0.2, thick] (a3) edge (c11);
			\path[->, draw=gray, opacity=0.2, thick] (a11) edge (c8);
			\path[->, draw=gray, opacity=0.2, thick] (a11) edge (c9);
			\path[->, draw=gray, opacity=0.2, thick] (a11) edge (c10);
			\path[->, draw=black, thick] (a11) edge (c11);

			\path[->, draw=gray, opacity=0.2, thick] (c8) edge (b5);
			\path[->, draw=gray, opacity=0.2, thick] (c8) edge (b6);
			\path[->, draw=gray, opacity=0.2, thick] (c8) edge (b7);
			\path[->, draw=gray, opacity=0.2, thick] (c9) edge (b5);
			\path[->, draw=gray, opacity=0.2, thick] (c9) edge (b6);
			\path[->, draw=gray, opacity=0.2, thick] (c9) edge (b7);
			\path[->, draw=gray, opacity=0.2, thick] (c10) edge (b5);
			\path[->, draw=gray, opacity=0.2, thick] (c10) edge (b6);
			\path[->, draw=gray, opacity=0.2, thick] (c10) edge (b7);
			\path[->, draw=gray, opacity=0.2, thick] (c11) edge (b5);
			\path[->, draw=black, thick] (c11) edge (b6);
			\path[->, draw=gray, opacity=0.2, thick] (c11) edge (b7);

			\path[->, draw=gray, opacity=0.2, thick] (b5) edge (t);
			\path[->, draw=black, thick] (b6) edge (t);
			\path[->, draw=gray, opacity=0.2, thick] (b7) edge (t);
		\end{tikzpicture}
		\subcaption{\label{subfig:layered-dag-solution} Solution generated in $G_{DAG}$.}
	\end{minipage}
	\caption{\label{fig:layered-dag-adaptation} Layered DAG Adaptation.}
\end{figure}

\begin{algorithm}[h!]
	\caption{Greedy Block Ordering Heuristic}\label{alg:greedy-block-ordering-heuristic}
	\SetAlgoLined
	\KwData{Blocks to visit $\mathcal{B}$, sorting option $sort\_opt$, block distance option $block\_distance\_opt$}
	\KwResult{Ordered sequence $\mathcal{B}'$ of blocks}

	$\mathcal{B}' \leftarrow \emptyset$\;
	$backup\_blocks \leftarrow \mathcal{B}$\;

	\tcp{Apply initial sorting strategy}
	\uIf{$sort\_opt = 0$}{
		Sort $backup\_blocks$ by cumulative hops (ascending)\;
	}
	\uElseIf{$sort\_opt = 1$}{
		Sort $backup\_blocks$ by number of nodes in the blocks (descending)\;
	}
	\uElseIf{$sort\_opt = 2$}{
		Sort $backup\_blocks$ by zero-hop count (descending)\;
	}
	\uElse{
		Shuffle $backup\_blocks$\;
	}

	\tcp{Iterative block selection}
	\While{$|connect\_order| < |\mathcal{B}|$}{
		\uIf{$\mathcal{B}'$ is empty}{
			Add first block from $backup\_blocks$ to $\mathcal{B}'$\;
			Find reference node with minimum distance to next block\;
		}

		$best\_block \leftarrow -1$, $min\_distance \leftarrow \infty$\;
		\For{each candidate block $b$ in $backup\_blocks$}{
			\uElseIf{$block\_distance\_opt = \text{B2B}$}{
				$(distance, ref\_node) \leftarrow \Call{MinBlock2BlockTime}{last\_ref\_block, b}$\;
			}
			\uElse {
				$(distance, ref\_node) \leftarrow$ \Call{MinNode2BlockTime}{$last\_ref\_node, b$}\;
			}
			$num\_nodes \leftarrow$ number of nodes in block $b$\;
			\If{$distance < min\_distance$ \textbf{or} ($distance = min\_distance$ \textbf{and} $num\_nodes > num\_best\_nodes$)}{
				$min\_distance \leftarrow distance$\;
				$best\_block \leftarrow b$\;
				$best\_ref\_node \leftarrow ref\_node$\;
			}
		}
		Add $best\_block$ to $\mathcal{B}'$\;
		Remove $best\_block$ from $backup\_blocks$\;
		$last\_ref\_node \leftarrow best\_ref\_node$\;
		$last\_ref\_block \leftarrow best\_block$\;

	}
	\Return{$\mathcal{B}'$}\;
\end{algorithm}

\section{Stochastic CBRP Heuristics}\label{sec:stochastic-heuristics}

This section presents the heuristics approaches developed to solve the \gls{scbrp}. The first step is to highlight the similarities between the deterministic and stochastic versions. Considering the formulation Path-SCBRP, presented in Section~\ref{sec:cbrp-stochastic-models}, the first relevant property is that the stochastic version of the problem is a set of $k = |S|$ independent \gls{cbrp} instances, one for each scenario $s \in S$ in the second stage considering a fixed first stage solution. Therefore, it is possible to use deterministic approaches to solve stages and scenarios independently. Besides the profit update that will be discussed in more detais latter in this section, the main steps to solve the \gls{scbrp} using a heuristic method are presented in Figure~\ref{fig:stochastic-local-search-heuristic}. The initial solution is generated using a variation of the constructive heuristic presented in Section~\ref{sec:greedy-constructive-algorithm}. The local search heuristic is then applied to the initial solution to improve the solutions of first and second stage, the heursitic consider a set of major criterias to explore seeking for improvements in the solution. At the end of a iterations, if some route improve is found, there is an option to propagates this improvement to other routes in the solution.

\begin{figure}[h!]
	\centering
	\begin{tikzpicture}
		[
			node distance=1.9cm, % distance between nodes
			font=\tiny,
			align=center
		]

		% Defining styles
		\tikzstyle{startstop} = [rectangle, minimum height = 1.2cm, minimum width = 2cm, rounded corners, text centered, draw=black, fill=gray!10!white]

		\tikzstyle{process} = [rectangle, rounded corners, minimum height = 1.2cm, minimum width = 2cm, text centered, draw=black, fill=blue!10!white]

		\tikzstyle{artificial} = [tape, draw=white, minimum width = 1cm, minimum height = 1cm]

		\tikzstyle{group-box} = [rectangle, rounded corners, draw=black, dashed]

		\tikzstyle{arrow} = [thick,->,>=stealth]

		% Create states
		\node (start) [process] at (0, 0) {Greedy Deterministic Heuristic\\for each scenario};

		% 
		\node (ls_route_improvement) [process, below of=start, yshift=-1.2cm] {Route\\Improvement};
		%
		\node (ls_out_route) [process, left of=ls_route_improvement, xshift=-0.5cm] {Out Route\\Swap};
		\node (ls_in_route) [process, left of=ls_out_route, xshift=-0.3cm] {In Route\\Swap};
		%
		\node (ls_add_block) [process, right of=ls_route_improvement, xshift=0.5cm] {Add Block\\to Route};
		\node (ls_remove_block) [process, right of=ls_add_block, xshift=0.3cm] {Remove Block\\from Route};

		\node (swap-box) [group-box, fit=(ls_in_route) (ls_out_route)] {};
		\node (swap_first) [startstop, below of=swap-box, yshift=-1.2cm] {Swap First\\Improve};
		\node (swap_random) [startstop, left of=swap_first, xshift=-0.3cm] {Swap Random\\Block};
		\node (swap_best) [startstop, right of=swap_first, xshift=0.3cm] {Swap Best\\Improve};

		\node (add-remove-box) [group-box, fit=(ls_add_block) (ls_remove_block)] {};
		\node (profit-change) [startstop, below of=add-remove-box, yshift=-1.2cm] {Profit Change};
		\node (time-change) [startstop, left of=profit-change, xshift=-0.3cm] {Time Change};
		\node (random-change) [startstop, right of=profit-change, xshift=0.3cm] {Random Change};

		% \node (improve-box) [group-box, fit=(swap_first) (swap_random) (swap_best) (profit-change) (time-change) (random-change)] {};

		\node (end) [process, below of = ls_route_improvement, yshift=-3.6cm] {Propagate Improvements to\\all routes in the solution};

		\node (sa-mean) [artificial, right of = random-change, xshift=0.5cm] {Heuristic Criteria};
		\node (ls-mean) [artificial, above of = sa-mean, yshift=1.2cm] {Local Search};
		\node (start-mean) [artificial, above of = ls-mean, yshift=1.2cm] {Initial Solution};
		\node (end-mean) [artificial, below of = sa-mean, yshift=-0.5cm] {Post-processing};

		% % Links
		\draw [arrow] (start) -- (swap-box) {};
		\draw [arrow] (start) -- (add-remove-box) {};
		\draw [arrow] (start) -- (ls_route_improvement) {};

		\draw [arrow] (swap-box) -- (swap_first) {};
		\draw [arrow] (swap-box) -- (swap_random) {};
		\draw [arrow] (swap-box) -- (swap_best) {};
		\draw [arrow] (add-remove-box) -- (profit-change) {};
		\draw [arrow] (add-remove-box) -- (time-change) {};
		\draw [arrow] (add-remove-box) -- (random-change) {};
		\draw [arrow] (ls_route_improvement) -- (end) {};

	\end{tikzpicture}
	\caption{Main Components of the Stochastic Local Search Heuristic.}
	\label{fig:stochastic-local-search-heuristic}
\end{figure}

\subsection{Initial Solution Heuristic}

Considering that the first stage and the scenarios of the second stage could be solve independently, the initial solution for the \gls{scbrp} could use the constructive heuristic presented in Section~\ref{sec:greedy-constructive-algorithm}.

The initial solution heuristic for the \gls{scbrp} is based on a two-stage approach that leverages deterministic greedy algorithms. In the first stage, all blocks are assigned adjusted profit values that combine both the nominal (first-stage) and scenario-based (second-stage) profits for each block, weighted by the reduction factor $\alpha$ and scenario probabilities. The greedy constructive algorithm is used to generate a feasible first-stage route that maximizes the aggregated profit while respecting the time constraint. Subsequently, for each scenario, the algorithm solves an independent routing problem where the profits associated with first-stage-visited blocks are appropriately reduced, reflecting the fact that those blocks have already been serviced. The greedy constructive algorithm is applied to each scenario with these adjusted profit values, producing scenario-specific routes. The overall solution consists of the first-stage routing plan together with a collection of scenario-dependent second-stage routes, thus providing a complete and feasible plan for the \gls{scbrp} as described in Algorithm~\ref{alg:greedy-constructive-algorithm}.

\begin{algorithm}[h!]
	\caption{Create Initial Solution}
	\SetAlgoLined
	\KwData{graph $G$, scenarios $S$, time limit $T$, blocks $B$, reduction factor $\alpha$, first-stage profit $p_b^{0}$, scenario profit $p_b^{\omega}$}
	\KwResult{Solution with first-stage route and scenario-specific routes}

	$solution \leftarrow \text{new Solution}(Input)$\;

	$cases\_per\_block \leftarrow \text{vector of size } |B|$\;
	$time\_per\_block \leftarrow \text{vector of size } B$\;

	\tcp{Set first-stage profit values for all blocks}
	\For{$b = 1$ \textbf{to} $|B|$}{
		$cases\_per\_block[b] \leftarrow p_{b}^{0} + \alpha \sum_{\omega \in \Omega} \xi^{\omega} p_{b}^{\omega}$\;
	}

	\tcp{Solve first stage using greedy heuristic and add to solution}
	$first\_stage\_of \leftarrow \Call{GreedyConstructiveAlgorithm}{cases\_per\_block, T, y_0}$\;
	Add first-stage allocation and route to solution\;

	\tcp{Solve Second Stage Problems for each scenario}
	\For{$s = 1$ \textbf{to} $S$}{
	\tcp{Adjust scenario costs based on first-stage solution}
	\For{$b = 1$ \textbf{to} $|B|$}{
	\uIf{$y_b^{0} = 1$}{
	$cases\_per\_block[b] \leftarrow (1 - \alpha) p_{b}^{s}$\;
	}\Else{
		$cases\_per\_block[b] \leftarrow p_{b}^{s}$\;
	}
	}
	$scn\_of \leftarrow \Call{GreedyConstructiveAlgorithm}{cases\_per\_block, T, y_s}$\;
	Add scenario allocation and route to solution\;
	$scn\_of \leftarrow \xi^{s} \times scn\_of$\;
	}
	\Return{$solution$}\;
\end{algorithm}

\subsection{Local Search Heuristic}

The local search is based on a set of major criterias to explore seeking for improvements in the initial solution. The criterias are presented in Figure~\ref{fig:stochastic-local-search-heuristic}. The starting point for swaps and other changes is the first stage route, then for each change in the blocks attended in the first stage route, the algorithm considers a set of possible swaps and other changes in the second stage routes.
Two swap changes in the objective function could be considered when a block in the first stage is changed, the first and simplier is to swap the block then only update the slice of profit for each second stage solution that is affected by the change, this objective evaluation is called ``weak''. The second option is to swap the block and also update the attended blocks in the second stage routes that are affected by the change, this objective evaluation is called ``moderate''.

The Algorithm~\ref{alg:run-default-perturbation} implements a hierarchical perturbation strategy for local search procedures. The algorithm attempts multiple types of neighborhood moves in a sequential manner, starting with less disruptive swaps and progressively exploring more aggressive perturbations until a feasible improving move is found. This multi-level approach balances solution quality with diversification needs.

\begin{algorithm}[h!]
	\caption{Local Search Default Perturbation} \label{alg:run-default-perturbation}
	\SetAlgoLined
	\KwData{Boolean flag $use\_random$ indicating random strategy selection}
	\KwResult{Change structure $\Delta$ containing the selected perturbation}

	$\Delta \leftarrow \emptyset$\;
	$strategy \leftarrow 0$\;
	\If{$use\_random$}{
		$strategy \leftarrow$ random integer in $\{0, 1, 2\}$\;
	}
	\tcp{Level 1 - In-route block swaps:}
	\If{$strategy = 0$}{
		$\Delta \leftarrow$ \Call{ComputeSwapBlocks}{$in\_route = true$}\;
	}
	\tcp{Level 2 - Out-route block swaps:}
	\If{$strategy = 1$ \textbf{or} $\Delta = \emptyset$}{
		$\Delta \leftarrow$ \Call{ComputeSwapBlocks}{$in\_route = false$}\;
	}
	\If{$\Delta \neq \emptyset$}{
		\Return{$\Delta$}\;
	}
	\tcp{Level 3 - Random block modifications:}
	$\Delta \leftarrow$ \Call{RandomBlockChange}{}\;
	\If{$\Delta \neq \emptyset$}{
		\Return{$\Delta$}\;
	}
	\Return{empty change}\;
\end{algorithm}

The algorithm implements a three-level hierarchical perturbation mechanism designed to systematically explore different neighborhood structures. At the first level, the algorithm attempts in-route block swaps, which exchange blocks that are already part of the current route but may have different attendance statuses. This represents the least disruptive perturbation and is often sufficient to escape local optima. If the random strategy flag is enabled, the algorithm randomly selects one of three initial strategies to enhance diversification. At the second level, if the first level fails to produce a valid change (either because it was skipped or returned an empty change), the algorithm explores out-route block swaps. These swaps exchange blocks currently in the route with blocks not yet included, representing a more aggressive perturbation that can significantly alter the solution structure. If both swap-based perturbations fail to generate valid moves, the algorithm proceeds to the third level, which applies random block modifications through the \textsc{RandomBlockChange} procedure. This final level includes random swap operations, block insertions, and block removals, providing the most aggressive diversification mechanism. The hierarchical structure ensures that the algorithm first attempts conservative moves that preserve solution quality, only resorting to more disruptive perturbations when necessary to escape stagnation.

The Algorithm~\ref{alg:compute-swap-blocks} identifies the best block swap operation in the first-stage solution by evaluating all feasible exchanges between attended blocks and candidate replacement blocks. The algorithm supports both in-route swaps (exchanging blocks within the current route) and out-route swaps (replacing route blocks with external blocks), using either weak or moderate delta evaluation strategies to assess solution quality changes.

\begin{algorithm}[h!]
	\caption{Compute Swap Blocks} \label{alg:compute-swap-blocks}
	\SetAlgoLined
	\KwData{Boolean $is\_out\_route$ indicating swap type}
	\KwResult{Change structure $\Delta^*$ with best swap and improvement value}

	$\Delta^* \leftarrow 0$, $b_1^* \leftarrow -1$, $b_2^* \leftarrow -1$\;
	$R \leftarrow$ first-stage route\;
	$\mathcal{B}_R \leftarrow$ blocks in route $R$\;

	\tcp{Evaluate all feasible swaps:}
	\For{each attended block $b_1 \in R$}{
		\eIf{$is\_out\_route$}{
			$\mathcal{C} \leftarrow$ all blocks not in route with positive profit\;
		}{
			$\mathcal{C} \leftarrow \mathcal{B}_R \setminus \{attended\ blocks\}$\;
		}
		\For{each candidate block $b_2 \in \mathcal{C}$}{
			\If{$b_1 = b_2$ \textbf{or} swap $(b_1, b_2)$ is infeasible}{
				\textbf{continue}\;
			}
			\tcp{Compute improvement delta}
			\eIf{$delta\_type = $ ``weak''}{
				$\Delta \leftarrow$ \Call{GetWeakDeltaSwapBlocks}{$b_1, b_2$}\;
				$swaps \leftarrow \emptyset$\;
			}{
				$\Delta \leftarrow$ \Call{GetModerateDeltaSwapBlocks}{$b_1, b_2, swaps$}\;
			}
			\tcp{Update best solution}
			\If{$\Delta > \Delta^*$}{
				$\Delta^* \leftarrow \Delta$, $b_1^* \leftarrow b_1$, $b_2^* \leftarrow b_2$\;
				$swaps^* \leftarrow swaps$\;
				\If{$use\_first\_improve$}{
					Add swap $(b_1^*, b_2^*)$ to $swaps^*$\;
					\Return{$(\Delta^*, swaps^*)$}\;
				}
			}
		}
	}
	\If{$b_1^* = -1$ \textbf{or} $b_2^* = -1$}{
		\Return{empty change}\;
	}
	Add first-stage swap $(b_1^*, b_2^*)$ to $swaps^*$\;
	\Return{$(\Delta^*, swaps^*)$}\;
\end{algorithm}

The algorithm explores the swap neighborhood by iterating through all attended blocks in the first-stage route and evaluating potential replacements. The search space is determined by the $is\_out\_route$ parameter: when true, candidate blocks include all blocks not currently in the route with positive profit, enabling exploration of completely new blocks; when false, candidates are restricted to unattended blocks already present in the route, resulting in more conservative moves. For each feasible swap pair $(b_1, b_2)$, the algorithm computes the objective function change using one of two evaluation strategies. The weak delta evaluation provides a fast approximation by considering only first-stage profits and direct second-stage impacts, while the moderate delta evaluation performs a more comprehensive analysis that accounts for cascading effects in second-stage scenarios, including potential block substitutions that may occur when first-stage decisions change.

The algorithm maintains the best swap found during the search, tracking both the improvement value $\Delta^*$ and the associated block pair $(b_1^*, b_2^*)$. When the moderate evaluation strategy is used, the algorithm also stores secondary swaps that should be applied to second-stage solutions to maintain consistency. The search can operate in two modes: best-improve mode, which exhaustively evaluates all swaps to find the best available move, or first-improve mode, which returns immediately upon finding any improving swap, trading solution quality for computational efficiency. This flexibility allows the algorithm to adapt to different computational budgets and optimization requirements.

The delta evaluation functions compute the change in objective value when swapping two blocks in the first-stage solution. The Algorithm~\ref{alg:get-weak-delta-swap-blocks} provides a fast approximation by considering only direct profit changes, while Algorithm~\ref{alg:get-moderate-delta-swap-blocks} performs a comprehensive analysis that accounts for cascading effects in second-stage scenarios, including potential block substitutions to maintain solution quality.

\begin{algorithm}[h!]
	\caption{Get Weak Delta Swap Blocks} \label{alg:get-weak-delta-swap-blocks}
	\SetAlgoLined
	\KwData{Block to remove $b_1$, block to insert $b_2$}
	\KwResult{Objective function change $\Delta$}

	\tcp{Initialize first-stage delta:}
	$\Delta \leftarrow p_{b_2} - p_{b_1}$\;
	$\alpha \leftarrow$ reduction factor\;

	\tcp{Evaluate second-stage impacts:}
	\For{each scenario $s = 1$ \textbf{to} $S$}{
		$\xi^{s} \leftarrow$ probability of scenario $s$\;
		$p_{b_1}^s \leftarrow$ profit in block $b_1$ for scenario $s$\;
		$p_{b_2}^s \leftarrow$ profit in block $b_2$ for scenario $s$\;
		\tcp{Account for first-stage reduction effect}
		$\Delta \leftarrow \Delta + \xi^{s} \cdot \alpha \cdot (p_{b_2}^s - p_{b_1}^s)$\;
		\tcp{Block $b_1$ leaving first-stage}
		\If{$b_1$ is attended in scenario $s$}{
			$\Delta \leftarrow \Delta + \alpha \cdot \xi^{s} \cdot p_{b_1}^s$\;
		}
		\tcp{Block $b_2$ entering first-stage}
		\If{$b_2$ is attended in scenario $s$}{
			$\Delta \leftarrow \Delta - \alpha \cdot \xi^{s} \cdot p_{b_2}^s$\;
		}
	}
	\Return{$\Delta$}\;
\end{algorithm}

The Algorithm~\ref{alg:get-weak-delta-swap-blocks} provides a computationally efficient way to compute the objective function change by evaluating only direct effects of the swap. The algorithm begins by computing the first-stage profit difference between the inserted block $b_2$ and removed block $b_1$.
It then iterates through all scenarios to account for second-stage impacts. The reduction factor $\alpha$ represents the fraction of cases that can be addressed in the second stage after being partially handled in the first stage. For each scenario, the algorithm adds the expected change in recaptured cases weighted by scenario probability. Additionally, if block $b_1$ was being attended in a scenario from second stage, its removal from the first stage allows those cases to be fully addressed in the second stage, contributing positively to the delta. Conversely, if block $b_2$ was attended in a second stage scenario, its promotion to the first stage reduces the second-stage profit, contributing negatively. This weak evaluation assumes no compensatory adjustments occur in second-stage solutions.

The Algorithm~\ref{alg:get-moderate-delta-swap-blocks} performs a more sophisticated analysis by identifying and evaluating potential compensatory swaps in second-stage scenarios. After computing the same first-stage and reduction effects as the weak evaluation, the algorithm examines each scenario for opportunities to maintain solution quality through block substitutions. When block $b_1$ leaves the first stage, if it was present but unattended in a scenario route and still has positive profit, the algorithm calls \textsc{GetBestSecondStageOptionIfB1Leaves} to identify the best currently-attended block that could be swapped out in favor of attending $b_1$. This substitution is recorded in the $swaps$ structure and its impact is added to the delta calculation. Similarly, when block $b_2$ enters the first stage, if it was being attended in a scenario from second stage, the algorithm calls \textsc{GetBestSecondStageOptionIfB2Enters} to find the best unattended block that could replace $b_2$ in the second-stage solution. This function considers the previous swap (if any) to avoid conflicts and ensure time feasibility. If a suitable replacement is found, the swap is recorded and its impact included in the delta. Otherwise, the algorithm accounts for the direct loss of $b_2$ second-stage contribution. This moderate evaluation provides a more accurate estimate of the true objective function change by anticipating rational adjustments to second-stage solutions.

\begin{algorithm}[h!]
	\caption{Get Moderate Delta Swap Blocks} \label{alg:get-moderate-delta-swap-blocks}
	\SetAlgoLined
	\KwData{Block to remove $b_1$, block to insert $b_2$, output $swaps$}
	\KwResult{Objective function change $\Delta$ and second-stage swaps}

	$\Delta \leftarrow p_{b_2} - p_{b_1}$\;
	$\alpha \leftarrow$ reduction factor\;
	$swaps \leftarrow \emptyset$\;

	\For{each scenario $s = 1$ \textbf{to} $S$}{
		$\xi^{s} \leftarrow$ probability of scenario $s$\;
		$R_s \leftarrow$ route for scenario $s$\;
		$p_{b_1}^s \leftarrow$ profit in block $b_1$ for scenario $s$\;
		$p_{b_2}^s \leftarrow$ profit in block $b_2$ for scenario $s$\;

		$\Delta \leftarrow \Delta + \xi^{s} \cdot \alpha \cdot (p_{b_2}^s - p_{b_1}^s)$; \tcp{First-stage reduction effect}

		\tcp{Handle block $b_1$ leaving first-stage}
		\eIf{$b_1$ is attended in $R_s$}{
			$\Delta \leftarrow \Delta + \alpha \cdot \xi^{s} \cdot p_{b_1}^s$\;
		}{
			\If{$b_1$ is in route $R_s$ \textbf{and} $p_{b_1}^s > 0$}{
				$b_{low} \leftarrow$ \Call{GetBestSecondStageOptionIfB1Leaves}{$s, b_1, b_2$}\;
				\If{$b_{low} \neq -1$}{
					$p_{low}^s \leftarrow$ updated profit for $b_{low}$ in $s$\;
					$\Delta \leftarrow \Delta + \xi^{s} \cdot (p_{b_1}^s - p_{low}^s)$\;
					Add $(s, (b_{low}, b_1))$ to $swaps$\;
				}
			}
		}

		\tcp{Handle block $b_2$ entering first-stage}
		\If{$b_2$ is attended in $R_s$}{
			$b_{high} \leftarrow$ \Call{GetBestSecondStageOptionIfB2Enters}{$s, b_1, b_2, time\_diff$}\;
			\eIf{$b_{high} \neq -1$}{
				$p_{high}^s \leftarrow$ updated profit for $b_{high}$ in $s$\;
				$p_{b_2}^s \leftarrow$ updated profit for $b_2$ considering first-stage\;
				$\Delta \leftarrow \Delta + \xi^{s} \cdot (p_{high}^s - p_{b_2}^s)$\;
				Add $(s, (b_2, b_{high}))$ to $swaps$\;
			}{
				$\Delta \leftarrow \Delta - \alpha \cdot \xi^{s} \cdot p_{b_2}^s$\;
			}
		}
	}
	\Return{$(\Delta, swaps)$}\;
\end{algorithm}

The diversification strategy referred in Algorithm~\ref{alg:run-default-perturbation} is described in Algorithm~\ref{alg:random-block-change}, which implements a randomized perturbation mechanism that selects and applies one of three block modification strategies: random swaps, insertions, or removals. This approach provides diversification in the search process by randomly choosing between different neighborhood structures, with each strategy employing specific selection criteria to identify promising moves.

\begin{algorithm}[h!]
	\caption{Random Block Change} \label{alg:random-block-change}
	\SetAlgoLined
	\KwData{Current solution with first-stage route}
	\KwResult{Change structure $\Delta$ containing the selected modification}

	\tcp{Random strategy selection:}
	$strategy \leftarrow$ random integer in $\{0, 1, 2\}$\;
	$option \leftarrow$ random integer in $\{0, 1, 2, 3\}$\;
	\eIf{$strategy = 0$}{
		$\Delta \leftarrow$ \Call{SelectRandomSwapBlocks}{}\;
	}{
		\eIf{$strategy = 1$}{
			$\Delta \leftarrow$ \Call{SelectInsertBlock}{$option$}\;
		}{
			$\Delta \leftarrow$ \Call{SelectRemoveBlock}{$option$}\;
		}
	}
	\If{$\Delta \neq \emptyset$}{
		\Return{$\Delta$}\;
	}
	\Return{\Call{SelectRemoveBlock}{$option$}}\;
\end{algorithm}

The Algorithm~\ref{alg:random-block-change} serves as a high-level dispatcher that randomly selects one of three perturbation strategies to diversify the current solution. The algorithm first generates two random values: one to determine the strategy type (swap, insert, or remove) and another to specify the selection criterion within insertion and removal operations (highest time, lowest profit, lowest profit-to-time ratio, or random selection). If the randomly selected strategy fails to produce a valid change, the algorithm defaults to attempting a block removal, ensuring that some perturbation is always considered.

The Algorithm~\ref{alg:select-random-swap-blocks} implements a swap strategy by randomly selecting a feasible swap pair from the solution space. It shuffles both attended and unattended blocks to identify a valid exchange that satisfies time and feasibility constraints. This randomization provides strong diversification without bias toward specific block characteristics. The delta evaluation follows the same weak or moderate strategy used throughout the local search framework. The swaps between blocks that already belong to a route are easy to evaluate and check feasibility, since there are no routing changes involved, only check if the the time change from removing the block and inserting the new one is feasible. The out-route swaps are more complex, since they involve routing changes, and need to be checked if the swap is feasible.

The function that determines whether swapping an attended block $b_1$ with a block $b_2$, that is not currently in the route, is feasible with respect to time constraints considers the complexity of taking account for both the removal of block $b_1$ (which may allow removal of a route node) and the insertion of block $b_2$ (which require adding a new node to the route).
The function begins by evaluating the time gain by removing the block $(b_1)$ from the solution, including both the block attendance time and any potential routing time savings if the node attending $b_1$ can be removed from the route when no other attended blocks depend on it.
The next time change is then calculated by subtracting this possible time gain from the time required to attend block $b_2$.
If this preliminary check indicates that even the best-case scenario would violate the time limit, the function immediately returns false.
Otherwise, the function systematically evaluates all possible insertion positions for block $b_2$ by iterating through consecutive node pairs in the current route.
For each position $(prev\_node, next\_node)$ in the current route, the procedure examines all nodes belonging to block $b_2$ and calculates the routing time change that would result from inserting that node between the pair. The insertion time is computed to determine the sum of distances from $prev\_node$ to the candidate node and from the candidate node to $next\_node$, minus the original direct distance from $prev\_node$ to $next\_node$.
If any insertion position and node combination results in a total time that does not exceed the time limit $T$, the swap is deemed feasible and the function returns true. If no feasible insertion position is found after examining all the possibilities, the function returns false, indicating that the out-route swap cannot be performed without violating time constraints.

\begin{algorithm}[h!]
	\caption{Select Random Swap Blocks} \label{alg:select-random-swap-blocks}
	\SetAlgoLined
	\KwData{First-stage route $R$}
	\KwResult{Change structure $\Delta$ with random feasible swap}

	\tcp{Identify feasible swap:}
	$(b_1, b_2) \leftarrow$ \Call{GetRandomBlocksFeasibleSwap}{$R$}\;
	\If{$b_1 = b_2$}{
		\Return{empty change}\;
	}
	\tcp{Compute swap delta:}
	\eIf{$delta\_type = $ ``weak''}{
		$\Delta \leftarrow$ \Call{GetWeakDeltaSwapBlocks}{$b_1, b_2$}\;
		$swaps \leftarrow \{(0, (b_1, b_2))\}$\;
	}{
		$\Delta \leftarrow$ \Call{GetModerateDeltaSwapBlocks}{$b_1, b_2, swaps$}\;
		Add $(0, (b_1, b_2))$ to $swaps$\;
	}
	\Return{$(\Delta, swaps)$}\;
\end{algorithm}

The insertion and removal functions employ four distinct selection strategies to identify which block should be inserted or removed from the first-stage solution. Each strategy targets blocks with specific characteristics that make them suitable candidates for insertion or removal, balancing different optimization objectives. After selecting the block to change, the function computes the objective function change using either weak or moderate delta evaluation, depending on the configured evaluation strategy. The block changing criteria are:

\begin{itemize}
	\item \textbf{Highest/Lowest Time:} Identifies and removes the attended block that consumes the most time in the route. This strategy frees up maximum capacity in the time budget, allowing for the potential insertion of multiple smaller blocks or providing flexibility for route improvements. It is particularly effective when the solution is near the time capacity limit and diversification through significant structural changes is desired. When the action is to insert a new block, the algorithm selects the block with the lowest time.

	\item \textbf{Highest/Lowest Profit:} Targets the attended block with the lowest total profit contribution, considering both first-stage and expected second-stage profits. This greedy approach focuses on improving solution quality by removing the least beneficial blocks, under the assumption that the freed capacity can be better utilized by alternative blocks. It is particularly useful when the solution contains blocks with marginal contributions. When the action is to insert a new block, the algorithm selects the block with the highest profit.

	\item \textbf{Highest/Lowest Profit-to-Time Ratio:} Selects the attended block with the lowest efficiency, measured as the ratio of profit to time consumption. This criterion balances both profit and time considerations, identifying blocks that provide poor value relative to their resource consumption. Removing inefficient blocks creates opportunities to insert blocks with better profit-to-time ratios, potentially improving overall solution efficiency. When the action is to insert a new block, the algorithm selects the block with the highest profit-to-time ratio.

	\item \textbf{Random Selection:} Randomly selects an attended block for removal without considering any specific criterion. The pure randomization provides maximum diversification in the search process, helping the algorithm escape local optima by exploring solution regions that might not be reached through greedy or efficiency-based selection. This option is particularly valuable in metaheuristic frameworks where diversification is crucial. When the action is to insert a new block, the algorithm selects a random feasible block, if it exists.
\end{itemize}

\subsection{Simulated Annealing Heuristic}

The Algorithm~\ref{alg:simulated-annealing-heuristic} implements a temperature-based stochastic local search that accepts both improving and non-improving moves with a probability that decreases as the temperature increases. This approach enables the algorithm to escape local optima by occasionally accepting worse solutions, with the acceptance probability controlled. The algorithm progressively increases the temperature, reducing the likelihood of accepting deteriorating moves as the search advances toward convergence.

\begin{algorithm}[h!]
	\caption{Simulated Annealing} \label{alg:simulated-annealing-heuristic}
	\SetAlgoLined
	\KwData{Input instance $I$, initial solution $S_0$}
	\KwResult{Best solution $S^*$ found during search}

	$S^* \leftarrow S_0$, $S_{curr} \leftarrow S_0$\;
	$OF^* \leftarrow$ objective value of $S^*$\;
	$Temperature \leftarrow T_{init}$\;

	\While{$Temperature < T_{max}$}{
		$improved \leftarrow false$\;
		\For{$iter \leftarrow 1$ \textbf{to} $max\_iterations$}{
			$\Delta, \text{swaps} \leftarrow $\Call{LocalSearchDefaultPerturbation}{}; \tcp{Generate perturbation}

			\If{$\text{swaps} = \emptyset$}{
				\textbf{continue to next iteration}\;
			}

			$p_{accept} \leftarrow \exp\left(\frac{\Delta \cdot Temperature}{OF^*}\right)$; \tcp{Compute acceptance probability}

			\eIf{$\Delta > 0$ \textbf{or} $random() < p_{accept}$}{
				Apply changes $\Delta$ to $S_{curr}$\;
			}{
				Reject changes\;
			}

			\tcp{Update best solution}
			\If{$OF(S_{curr}) > OF^*$}{
				$S^* \leftarrow S_{curr}$\;
				$OF^* \leftarrow OF(S_{curr})$\;
				$improved \leftarrow true$\;
			}
		}
		\tcp{Improve second-stage routes}
		\eIf{$improved$}{
			\Call{ImproveSecondStageRoutes}{$S^*$}\;
			$S_{curr} \leftarrow S^*$\;
		}{
			\Call{ImproveSecondStageRoutes}{$S_{curr}$}\;
		}
		$Temperature \leftarrow Temperature \times \alpha$\;
	}
	$S^* \leftarrow$ \Call{PostProcessing}{$S^*$}\;
	\Return{$S^*$}\;
\end{algorithm}

The Simulated Annealing algorithm implements a metaheuristic search strategy that balances intensification and diversification through a temperature-controlled acceptance mechanism. The algorithm maintains two solutions throughout the search: the current solution $S_{curr}$, which undergoes perturbations and may temporarily deteriorate, and the best solution $S^*$, which tracks the highest-quality solution encountered. The search operates through nested loops, with an outer loop that progressively increases the temperature from an initial value $T_{init}$ to a maximum value $T_{max}$, and an inner loop that performs a fixed number of iterations at each temperature level. At each iteration, the algorithm generates a perturbation using the \textsc{LocalSearchDefaultPerturbation} which applies one of several neighborhood operators (swaps, insertions, removals, or route improvement) to modify the current solution.

The acceptance decision follows the criterion: improving changes(positive delta) are always accepted, while deteriorating changes are accepted with probability $p_{accept} = \exp(\Delta \cdot Temperature / OF^*)$, where $\Delta$ is the change in objective value, $Temperature$ is the current temperature, and $OF^*$ is the best objective value found so far. This formulation ensures that at higher temperatures (later in the search), the algorithm behaves more conservatively, accepting fewer deteriorating changes, while at lower temperatures (earlier in the search), it becomes more exploratory, accepting worse solutions more readily to escape local optima.
When the current solution surpasses the best solution, both are updated to maintain the best-found solution.

At the end of each temperature level, the algorithm \textsc{ImproveSecondStageRoutes} is applied to optimize the second-stage scenario solutions using a greedy heuristic, ensuring that the stochastic component of the problem is properly addressed. If the best solution improved during the temperature level, the current solution is reset to the best solution to intensify the search around promising regions, otherwise, only the current solution is improved to continue diversification. The temperature is then multiplied by a cooling factor $\alpha > 1$ (heating schedule) to increase the temperature for the next level. After completing all temperature levels, a final post-processing step refines the best solution by re-solving all scenario block selection subproblems to the best feasible know route, ensuring solution quality before returning the final result.

\section{Dengue Virus Spread Simulation}\label{sec:dengue-virus-spread-simulation}

This section presents the design and implementation of the proposed \gls{mabs}
following the compartmental theory~\citep{amaku:2014}. The model adopts a SIR
compartment for human agents and SEI for mosquitoes. Birth and death rates are
considered for the mosquito population, while the human population remains
constant throughout all simulations. Transitions from susceptible to infected
(or exposed) occur based on interactions between a susceptible agent and an
infected agent of the opposite species.

Table~\ref{tab:parameters-mabs} presents the description of the model parameters
as well as their chosen values. Most parameter values are based on those
explored in the works of~\cite{da-silva:2020} and \cite{dwivedi:2022}. The other
parameters, especially those that established the generation of new mosquitoes,
are adjusted with experiments discussed in
Section~\ref{sec:computational-experiments}.

% Parameters
\begin{table}[!ht]
	\centering
	\caption{\label{tab:parameters-mabs} Static parameters used in the proposed
		\gls{mabs}.} \small{%
		\begin{tabular}{clr}
			\toprule
			\textbf{Parameter} & \textbf{Description}                                  & \textbf{Value} \\ \midrule
			$\gamma_H$         & Human recovery rate per day                           & 0.146          \\ \hline
			$a$                & Daily rate of bites                                   & 0.168          \\ \hline
			$b$                & Fraction of infectious bites                          & 0.600          \\ \hline
			$\gamma_M$         & Mosquito latency rate per day                         & 0.143          \\ \hline
			$c$                & Mosquito susceptibility to dengue                     & 0.526          \\ \hline
			$\rho$             & The percentage of eggs that produce female mosquitoes & 0.125
			\\ \hline
			$\phi$             & Mosquito daily oviposition rate                       & 0.020          \\ \hline
			$\omega$           & Carrying capacity of the mosquito                     & 3.000          \\
			\hline
			$\delta$           & Mosquito daily mortality rate in aquatic phase        & 0.066          \\ \hline
			$\sigma$           & Mosquito daily maturation rate                        & 0.100          \\ \hline
			$\mu_M$            & Mosquito daily mortality rate in adult phase          & 0.010
			\\ \hline
			$\Delta_M$         & Daily rate of eggs to female adult mosquitoes         &
			0.125                                                                                       \\
			\bottomrule
		\end{tabular}%
	}
\end{table}

Each value in Table~\ref{tab:parameters-mabs} represents the probability applied
to agents in the simulation in each cycle. The parameter $\gamma_H$ denotes the
likelihood of a human transitioning from Infected to Recovered. The parameter
$a$ indicates the chance of a human being bitten by a nearby mosquito, while $b$
represents the probability that a bite from an infected mosquito is infectious.
The transition of a mosquito from exposed to infected depends on $\gamma_M$. If
a mosquito bites an infected human, the probability of the mosquito becoming
infected is given by $c$. The parameter $\rho$ signifies the number of eggs that
hatch into female mosquitoes, $\phi$ is the likelihood of a mosquito laying eggs
due to an interaction with a breeding site, and $\omega$ represents the maximum
number of eggs deposited per interaction. The parameter $\delta$ indicates the
probability of an egg dying, while $\sigma$ is the probability of it developing
into an adult susceptible mosquito. Finally, $\mu_M$ is the adult mosquito
mortality rate.

\subsection{MABS Agents} \label{sec:agents}

The model has four types of agents that could have some interactions with each
other: mosquito, human, egg, and breeding site. The sizes of the human and
breeding site populations do not change during the simulation. The mosquito
agent is divided into two phases: aquatic and adult. The breeding site agent
represents a point on the map that allows mosquitoes to lay eggs to proliferate
new individuals for the population, independent of the current state. The
mosquitoes in the starting population and those generated during the simulation
are associated with a breeding site.

This work does not consider vertical transmission, i.e., mosquitoes do not
transmit the virus to eggs in the breeding sites. This information implies that
all mosquitoes changing from the aquatic to adult phase in a breeding site start
as susceptible. A simplified flowchart of interactions is presented in
Figure~\ref{fig:simplified-agent-interaction}, followed by a more detailed
description.

\begin{figure}[!ht]
	\begin{tikzpicture}[ node distance = 4.0cm, block/.style = {rectangle, draw,
					minimum width=2cm, minimum height=1cm, fill=lightgray, rounded corners,
					fill opacity=0.4, text=black, text opacity=1.0}, arrow/.style = {->,
					thick}, dashedarrow/.style = {->, thick, dashed}, dashedbox/.style =
				{draw, dashed, inner sep=10pt, rounded corners, opacity=0.2}
			% Define dashed box style
		]

		% Nodes
		\node (P) {Human}; \node [block, right of=P, xshift=-1cm] (S)
		{Susceptible}; \node [block, right of=S, xshift=1.5cm] (I) {Infected};
		\node [block, right of=I] (R) {Recovered};
		% \node[dashedbox, fit=(S) (I) (R)] (Box) {};

		% Arrows
		\draw [arrow] (S) -- (I) node[midway, above, color=black] {$1 - (1 - a
				\times b)^{n_{I}}$}; \draw [arrow] (I) -- (R) node[midway, above,
			color=black] {$\gamma_H$};

		\node [below of=P, yshift=2cm] (M) {Mosquitoes}; \node [block, right
			of=M, below of=P, yshift=2cm, xshift=-1cm] (SM) {Susceptible}; \node
		[block, right of=SM, below of=S, yshift=2cm, xshift=1.5cm] (EM)
		{Exposed}; \node [block, right of=EM, below of=I, yshift=2cm] (IM)
		{Infected};

		\node[dashedbox, fit=(SM) (EM) (IM)] (Box2) {};

		% Arrows
		\draw [arrow] (SM) -- (EM) node[midway, below, color=black] {$1 - (1 - a
				\times c)^{m_i}$}; \draw [arrow] (EM) -- (IM) node[midway, below,
			color=black] {$\gamma M$};

		\draw [dashedarrow, color=gray] (SM) -- (I) node[midway, above,
			color=black] {$a$}; \draw [dashedarrow, color=gray] (IM) -  - (S)
		node[midway, above, color=black] {$b$};

		%
		\node [below of=M, yshift=1cm] (AQ) {Aquatic Stage}; \node [block, right
			of=B, below of=M, yshift=1cm, xshift=-1cm] (EGG) {Egg};

		\node [block, right of=EGG, below of=SM, yshift=1cm, xshift=1.5cm] (BS)
		{Breeding Site};

		\draw [dashedarrow, color=gray] (Box2) -- (BS) node[midway, right,
			color=black] {$\omega$};

		\draw [dashedarrow, color=gray] (BS) -- (EGG) node[midway, above,
			color=black] {$(1 - \delta)$};

		\draw [dashedarrow, color=gray] (EGG) -- (SM) node[midway, left,
			color=black] {$(\sigma \times \rho)$};

		%
		% \node [below of=AQ, yshift=1cm] (BS) {Breeding Site:}; \node [block,
		% right of=BS, below of=EGG, yshift=1cm] (EGG) {Egg};
	\end{tikzpicture}

	\caption{Simplified agent interaction flowchart.}
	\label{fig:simplified-agent-interaction}
\end{figure}


\begin{itemize}
	\item \textbf{Human Agent:}
	      \begin{itemize}
		      \item \textbf{Location}: For each human, two blocks are randomly defined to
		            represent work and resting places. The exact point inside of each block is
		            also defined randomly.
		      \item \textbf{Move}: Considering the basic people's routines, they cycle
		            every day between two locations. It is assumed that humans have a residence
		            and a destination point, which may be, for example, school or work. The
		            movement is based on daily hours; each human has a ``$start\_work\_time$"
		            that is a time between 5 AM and 8 AM, indicating the time when the agent
		            starts to move from home to its destination, setting the current objective
		            to ``working". The ``$end\_work\_time$" follows the same pattern,
		            representing the return home between 4 PM and 7 PM, changing the current
		            objective to ``resting''.
		      \item \textbf{Change to Infected state}: Changing a human agent from
		            susceptible to infected requires interaction with infected mosquitoes. The
		            higher the number of infected mosquitoes nearby, the greater the chance of
		            this state transition. Assume $n_I$ as the number of infected mosquitoes
		            within a 1-meter distance and the probability of a human being infected by
		            the bite of an infected mosquito. From these values, consider $(a \times b)$
		            as the probability of a human becoming infected. Thus, the chance of
		            changing from a susceptible to an infected state is given by $1 - (1 - a
			            \times b)^{n_{I}}$.
		      \item  \textbf{Change to Recovered state}: Changing from infected to
		            recovered depends on the parameter $\gamma_H$.
	      \end{itemize}

	\item \textbf{Breeding Site Agent.}
	      \begin{itemize}
		      \item \textbf{Location}: Each breeding site is located at a random point
		            inside a street block.
		      \item \textbf{Create new eggs}: When a mosquito lays an egg at a breeding
		            site, this interaction creates a new Egg agent in the simulation. This new
		            egg is associated with the breeding site, and this decision impacts the
		            movement range of the adult mosquito.
	      \end{itemize}

	\item \textbf{Egg Agent.}
	      \begin{itemize}
		      \item \textbf{Location}: All Egg agents are located inside breeding sites.
		      \item \textbf{Change to  Adult phase}: The change from aquatic to adult
		            phase depends on the maturation rate ($\sigma$), and the successfully
		            hatched egg rate ($\rho$). The probability of an egg changing to the adult
		            stage is given by $\sigma \times \rho$.
		      \item \textbf{Aquatic Phase Death}: The death of an egg in the aquatic phase
		            depends on the mortality rate ($\delta$).
	      \end{itemize}

	\item \textbf{Mosquito Agent.}
	      \begin{itemize}
		      \item \textbf{Location}: Each mosquito is associated with a Breeding Site,
		            and its starting location is a random point inside a circle with a
		            $100$-meter radius, centered on the breeding site.
		      \item \textbf{Move}: Each mosquito has a $20\%$ chance of remaining
		            stationary during the cycle. If the agent decides to move, this action is
		            carried out randomly and at a random distance from the current location.
		            However, the destination is always close to the starting point, limited by a
		            radius of $100$ meters from the associated breeding site.
		      \item  \textbf{Oviposition}: The frequency and quantity of eggs that
		            mosquitoes lay depend on the number of breeding sites nearby (specifically,
		            within one meter of the current location), the oviposition rate ($\phi$),
		            and the biotic capacity of the mosquitoes ($\omega$). Each mosquito selects
		            a random breeding site, and based on $\phi$, the mosquitoes can lay a random
		            number of eggs ranging from $1$ to $\omega$.
		      \item \textbf{Change to Exposed state}: changing from susceptible to exposed
		            depends on the number of infected humans nearby. The larger this number, the
		            greater the chance of changing the state. Considering $a$ as the average
		            bite rate per day, $c$ as the probability of the mosquito being infected by
		            the virus, and $m_I$ as the number of infected people in the vicinity of the
		            mosquito, the probability of a mosquito changing from susceptible to
		            infected is given by $1 - (1 - a \times c)^{m_I}$.
		      \item \textbf{Change to  Infected state}: The transition from the exposed to
		            the infected state in mosquitoes is governed by the parameter $\gamma_M$.
		      \item \textbf{Die}: The death of the mosquitoes can occur during any state,
		            and the chance is given by the parameter $\mu_M$.
	      \end{itemize}
\end{itemize}

The flow of time in the simulation is based on cycles. Each cycle represents a
moment in time during which all agents perform their specific actions. In this
work, each cycle represents a time skip of 12 hours. Since the simulation runs
over real dates, the starting hour of the initial date of the simulation is
05:30 AM. This decision ensures that all cycles occur at 05:30 AM/PM, which are
moments of thermal inversions known as the most active time for mosquitoes. In
addition, these hours divide the human population into work and home locations.

The model implementation was developed in the GAMA
Platform\footnote{\url{https://gama-platform.org/}}~\citep{taillandier:2019}, a
tool designed specifically for \gls{mabs}. GAMA operates using a modeling
language called GAML (Gama Modeling Language), which is an agent-oriented
language. This means that everything active in the model can be represented in
GAMA as an agent. GAMA provides an interface to manipulate input/output data
from the simulation, which enables integration with other tools that interact
with the agents of the simulation. Figure~\ref{fig:example-gama} illustrates a
geospatial agent-based simulation of dengue transmission dynamics in
\textit{Alto Santo}, Brazil, modeled in the GAMA platform using \gls{osm} data.
Human populations are represented as yellow dots, red dots denote \textit{Aedes
	aegypti} mosquito population and black nodes are breeding sites. Potential
breeding sites are excluded from this visualization layer, as their simulated
locations are confined to street blocks. This simplification ensures visual
clarity while retaining the models focus on human-mosquito spatial
interactions.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=16cm, height=10cm]{images/gama-example.png}
	\caption{Geographic view in GAMA platform.}
	\label{fig:example-gama}
\end{figure}
